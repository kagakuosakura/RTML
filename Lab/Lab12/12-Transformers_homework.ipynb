{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 12: Transformers, Speech Recognition\n",
    "\n",
    "In this lab, we'll go through two tutorials, one on the Transformer architecture and one\n",
    "on end-to-end training of a (recurrent) speech recognition system.\n",
    "\n",
    "The open question will be whether we can adapt the Transformer to the speech recognition task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer With Torchtext\n",
    "\n",
    "First, let's see how to train a sequence-to-sequence model that uses the `nn.Transformer` module\n",
    "and the torchtext module in PyTorch.\n",
    "\n",
    "This is from [the Pytorch Transformer tutorial](https://pytorch.org/tutorials/beginner/transformer_tutorial.html).\n",
    "\n",
    "The Transformer as we know has obtained superior results in many sequence to sequence problems. PyTorch's\n",
    "nn.Transformer module implements the Transformer, especially the attention mechanism\n",
    "(implemented in `nn.MultiheadAttention`) to model the global dependencies between elements of the input sequence,\n",
    "elements of the output sequence, and input-output dependencies.\n",
    "The `nn.Transformer` module is highly modularized, so we can use a single component\n",
    "(`nn.TransformerEncoder` in this tutorial) can be easily adapted/composed.\n",
    "\n",
    "<img src=\"img/transformer.png\" title=\"transformer\" style=\"width: 400px;\" />\n",
    "\n",
    "### Language modeling task\n",
    "\n",
    "Our goal will be to assign a probability for the likelihood of a given word (or a sequence of words) following a sequence of words.\n",
    "A sequence of tokens is passed to an embedding layer first, followed by a positional encoding layer that accounts for the ordering of the words.\n",
    "\n",
    "### The model\n",
    "\n",
    "The TransformerEncoder consists of multiple layers of\n",
    "TransformerEncoderLayer. Along with the input sequence, we'll use an attention mask so that the self-attention layers in the\n",
    "TransformerEncoder are only allowed to attend the earlier positions in the sequence\n",
    "(in this language modeling task, tokens in the future positions should be masked).\n",
    "To form output words, the output of the TransformerEncoder model is sent to a final Linear layer, which is followed by a log-Softmax function.\n",
    "\n",
    "### PositionalEncoding module\n",
    "\n",
    "The PositionalEncoding module injects information about\n",
    "relative or absolute positions of the tokens in the sequence. Positional encodings have the same dimension\n",
    "as embeddings, so that the two can be summed. Here, as in the original Transformer paper,\n",
    "\n",
    "we use sine and cosine functions of different frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "from comet_ml import Experiment\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "This lab uses the Wikitext-2 dataset via the `torchtext` module.\n",
    "The vocabulary object is built based on the training dataset and is used to embed tokens into tensors.\n",
    "Starting from sequential data, the `batchify()` function arranges the dataset into columns, trimming off\n",
    "any tokens remaining after the data has been divided into batches of size batch_size. For instance, with the alphabet\n",
    "as the sequence (total length of 26) and a batch size of 4, we can divide the alphabet into 4 sequences of length 6:\n",
    "\n",
    "\\begin{split}\\begin{bmatrix}\n",
    "\\text{A} & \\text{B} & \\text{C} & \\ldots & \\text{X} & \\text{Y} & \\text{Z}\n",
    "\\end{bmatrix}\n",
    "\\Rightarrow\n",
    "\\begin{bmatrix}\n",
    "\\begin{bmatrix}\\text{A} \\\\ \\text{B} \\\\ \\text{C} \\\\ \\text{D} \\\\ \\text{E} \\\\ \\text{F}\\end{bmatrix} &\n",
    "\\begin{bmatrix}\\text{G} \\\\ \\text{H} \\\\ \\text{I} \\\\ \\text{J} \\\\ \\text{K} \\\\ \\text{L}\\end{bmatrix} &\n",
    "\\begin{bmatrix}\\text{M} \\\\ \\text{N} \\\\ \\text{O} \\\\ \\text{P} \\\\ \\text{Q} \\\\ \\text{R}\\end{bmatrix} &\n",
    "\\begin{bmatrix}\\text{S} \\\\ \\text{T} \\\\ \\text{U} \\\\ \\text{V} \\\\ \\text{W} \\\\ \\text{X}\\end{bmatrix}\n",
    "\\end{bmatrix}\\end{split}\n",
    "\n",
    "These columns are treated as independent by the model, which means that the dependence of G and F can not be learned, but allows more efficient batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import torch\n",
    "from torchtext.datasets import WikiText103, WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "train_iter = WikiText2(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "counter = Counter()\n",
    "for line in train_iter:\n",
    "    counter.update(tokenizer(line))\n",
    "vocab = Vocab(counter)\n",
    "\n"
   ]
  },
  {
   "source": [
    "I use validation set of WikiText103 as my test set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(raw_text_iter):\n",
    "  data = [torch.tensor([vocab[token] for token in tokenizer(item)],\n",
    "                       dtype=torch.long) for item in raw_text_iter]\n",
    "  return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "val_iter = WikiText103(split='valid')\n",
    "val_data = data_process(val_iter)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def batchify(data, bsz):\n",
    "    # Divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "val_data = batchify(val_data, eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate input and target sequences\n",
    "\n",
    "Here is the idea of input and target sequences. As always with\n",
    "time sequences in PyTorch, the tensor dimensions are (time x batch element):\n",
    "\n",
    "<img src=\"img/transformer_input_target1.png\" title=\"input-target\" style=\"width: 400px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 35\n",
    "def get_batch(source, i):\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model\n",
    "\n",
    "Next let's initialize the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=200, out_features=200, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=200, out_features=200, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): Embedding(28783, 200)\n",
       "  (decoder): Linear(in_features=200, out_features=28783, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "ntokens = len(vocab.stoi) # the size of vocabulary\n",
    "emsize = 200 # embedding dimension\n",
    "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)\n",
    "# load model\n",
    "model.load_state_dict(torch.load('./models/TransformerModel_3.weight'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model\n",
    "\n",
    "Now let's train it. Note that in the language modeling\n",
    "community, exp(negative log likelihood) is called \"Perplexity\"\n",
    "and abbreviated PPL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "import time\n",
    "def train():\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        optimizer.zero_grad()\n",
    "        if data.size(0) != bptt:\n",
    "            src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "        output = model(data, src_mask)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = 200\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    epoch, batch, len(train_data) // bptt, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(data_source, i)\n",
    "            if data.size(0) != bptt:\n",
    "                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "            output = eval_model(data, src_mask)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(data_source) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_val_loss = float(\"inf\")\n",
    "# epochs = 3 # The number of epochs\n",
    "# best_model = None\n",
    "\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#     epoch_start_time = time.time()\n",
    "#     train()\n",
    "#     val_loss = evaluate(model, val_data)\n",
    "#     print('-' * 89)\n",
    "#     print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "#           'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "#                                      val_loss, math.exp(val_loss)))\n",
    "#     print('-' * 89)\n",
    "\n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         best_model = model\n",
    "\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=========================================================================================\n| End of training | test loss  5.65 | test ppl   283.99\n=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model, val_data)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
    "    test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end (Recurrent) Speech Recognition Model\n",
    "\n",
    "Now let's look at an example of how to do sound processing\n",
    "in PyTorch using the torchaudio module.\n",
    "\n",
    "This tutorial is from [Assembly AI's blog on end-to-end speech recognition](https://www.assemblyai.com/blog/end-to-end-speech-recognition-pytorch).\n",
    "\n",
    "Other references:\n",
    "- https://colab.research.google.com/drive/1IPpwx4rX32rqHKpLz7dc8sOKspUa-YKO#scrollTo=RVJs4Bk8FjjO\n",
    "- https://pytorch.org/tutorials/intermediate/speech_command_recognition_with_torchaudio.html (base code)\n",
    "\n",
    "The model we'll build is inspired by Deep Speech 2 from Baidu with some improvements by Assembly AI.\n",
    "The output of the model is a probability matrix of characters, which will be decoded to the most likely sequence of characters spoken in the audio.\n",
    "\n",
    "### Prepare dataset\n",
    "\n",
    "Data is one of the most important aspects of speech recognition. We'll take raw audio waves and transform them into Mel Spectrograms.\n",
    "\n",
    "<img src=\"img/transformer_spectrograms.png\" title=\"Mel Spectrograms\" style=\"width: 480px;\" />\n",
    "\n",
    "For handling the audio data, we are going to use an extremely useful utility called torchaudio which is a library built by the PyTorch team specifically for audio data. We'll be training on a subset of LibriSpeech (http://www.openslr.org/12/), which is a corpus of read English speech data derived from audiobooks, comprising 100 hours of transcribed audio data. You can easily download this dataset using torchaudio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from comet_ml import Experiment\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchaudio.datasets.SPEECHCOMMANDS(\"./data\", url=\"speech_commands_v0.02\", download=True, subset='testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of waveform: torch.Size([1, 16000])\nSample rate of waveform: 16000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ],
      "text/html": "\n                <audio  controls=\"controls\" >\n                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n                    Your browser does not support the audio element.\n                </audio>\n              "
     },
     "metadata": {},
     "execution_count": 11
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 387.552405 248.518125\" width=\"387.552405pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 387.552405 248.518125 \nL 387.552405 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 44.845313 224.64 \nL 379.645313 224.64 \nL 379.645313 7.2 \nL 44.845313 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m99bd61bf1e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"60.063494\" xlink:href=\"#m99bd61bf1e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(56.882244 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"98.111327\" xlink:href=\"#m99bd61bf1e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2000 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(85.386327 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"136.159159\" xlink:href=\"#m99bd61bf1e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4000 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(123.434159 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"174.206992\" xlink:href=\"#m99bd61bf1e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6000 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(161.481992 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"212.254824\" xlink:href=\"#m99bd61bf1e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8000 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(199.529824 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"250.302657\" xlink:href=\"#m99bd61bf1e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10000 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(234.396407 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"288.35049\" xlink:href=\"#m99bd61bf1e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 12000 -->\n      <g transform=\"translate(272.44424 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"326.398322\" xlink:href=\"#m99bd61bf1e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 14000 -->\n      <g transform=\"translate(310.492072 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"364.446155\" xlink:href=\"#m99bd61bf1e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 16000 -->\n      <g transform=\"translate(348.539905 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m922f059a14\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m922f059a14\" y=\"202.713815\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- −0.75 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(7.2 206.513034)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m922f059a14\" y=\"173.58699\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- −0.50 -->\n      <g transform=\"translate(7.2 177.386209)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m922f059a14\" y=\"144.460164\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- −0.25 -->\n      <g transform=\"translate(7.2 148.259383)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m922f059a14\" y=\"115.333339\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.00 -->\n      <g transform=\"translate(15.579688 119.132558)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m922f059a14\" y=\"86.206514\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.25 -->\n      <g transform=\"translate(15.579688 90.005732)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m922f059a14\" y=\"57.079688\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.50 -->\n      <g transform=\"translate(15.579688 60.878907)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#m922f059a14\" y=\"27.952863\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.75 -->\n      <g transform=\"translate(15.579688 31.752082)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#p0bbf68628e)\" d=\"M 60.063494 115.329784 \nL 85.441399 115.230229 \nL 85.460423 115.201785 \nL 85.479446 115.276451 \nL 85.517494 115.283562 \nL 85.555542 115.411561 \nL 85.631638 115.312006 \nL 85.840901 115.322673 \nL 85.878949 115.347561 \nL 85.993092 115.198229 \nL 86.069188 115.379561 \nL 86.12626 115.34045 \nL 86.278451 115.290673 \nL 86.411618 115.425783 \nL 86.449666 115.390227 \nL 86.56381 115.329784 \nL 86.582834 115.255118 \nL 86.658929 115.37245 \nL 86.696977 115.40445 \nL 86.754049 115.344006 \nL 86.868192 115.358228 \nL 87.00136 115.361783 \nL 87.020384 115.376005 \nL 87.058432 115.287117 \nL 87.248671 115.280006 \nL 87.305742 115.408005 \nL 87.362814 115.358228 \nL 87.400862 115.255118 \nL 87.457934 115.379561 \nL 87.648173 115.383116 \nL 87.78134 115.280006 \nL 88.047675 115.297784 \nL 88.066699 115.248007 \nL 88.123771 115.312006 \nL 88.237914 115.347561 \nL 88.352058 115.244451 \nL 88.523273 115.393783 \nL 88.675464 115.283562 \nL 88.789608 115.408005 \nL 88.827656 115.358228 \nL 88.884727 115.276451 \nL 88.941799 115.347561 \nL 89.055943 115.425783 \nL 89.093991 115.383116 \nL 89.170086 115.248007 \nL 89.208134 115.319117 \nL 89.341301 115.358228 \nL 89.474469 115.415116 \nL 89.512517 115.272895 \nL 89.588612 115.333339 \nL 89.645684 115.304895 \nL 89.72178 115.379561 \nL 89.797875 115.244451 \nL 89.854947 115.329784 \nL 89.950067 115.322673 \nL 89.988115 115.230229 \nL 90.06421 115.272895 \nL 90.235426 115.411561 \nL 90.387617 115.312006 \nL 90.482736 115.26934 \nL 90.539808 115.422227 \nL 90.768095 115.276451 \nL 91.015406 115.329784 \nL 91.12955 115.351117 \nL 91.281741 115.290673 \nL 91.414908 115.40445 \nL 91.433932 115.386672 \nL 91.548076 115.351117 \nL 91.586124 115.280006 \nL 91.643195 115.333339 \nL 91.700267 115.397338 \nL 91.757339 115.333339 \nL 91.795387 115.354672 \nL 91.871482 115.322673 \nL 91.985626 115.393783 \nL 92.023674 115.351117 \nL 92.175865 115.347561 \nL 92.309032 115.415116 \nL 92.499272 115.30845 \nL 92.632439 115.379561 \nL 92.746582 115.230229 \nL 92.765606 115.297784 \nL 92.87975 115.290673 \nL 92.955846 115.37245 \nL 92.993893 115.336895 \nL 94.230448 115.390227 \nL 94.306544 115.440005 \nL 94.268496 115.34045 \nL 94.325568 115.329784 \nL 94.439711 115.390227 \nL 94.458735 115.315561 \nL 94.553855 115.344006 \nL 94.782142 115.23734 \nL 94.801165 115.379561 \nL 94.896285 115.283562 \nL 94.972381 115.248007 \nL 95.086524 115.351117 \nL 96.798677 115.26934 \nL 96.817701 115.20534 \nL 96.855748 115.354672 \nL 96.874772 115.347561 \nL 97.35037 115.386672 \nL 97.464514 115.184007 \nL 97.578657 115.34045 \nL 97.692801 115.301339 \nL 97.825968 115.386672 \nL 97.940112 115.301339 \nL 97.978159 115.351117 \nL 100.831747 115.368894 \nL 100.850771 115.20534 \nL 100.926866 115.411561 \nL 100.94589 115.272895 \nL 101.060034 115.457782 \nL 101.174177 115.240896 \nL 101.193201 115.383116 \nL 101.288321 115.361783 \nL 101.38344 115.411561 \nL 101.402464 115.336895 \nL 101.497584 115.30845 \nL 101.516608 115.322673 \nL 101.859038 115.333339 \nL 102.030254 115.301339 \nL 102.182445 115.37245 \nL 102.486828 115.290673 \nL 102.639019 115.40445 \nL 102.734139 115.37245 \nL 102.810234 115.276451 \nL 102.848282 115.322673 \nL 102.943402 115.379561 \nL 102.962426 115.322673 \nL 103.285832 115.333339 \nL 103.399976 115.393783 \nL 103.533143 115.336895 \nL 103.66631 115.333339 \nL 103.76143 115.386672 \nL 103.780454 115.315561 \nL 103.799478 115.400894 \nL 103.875573 115.26934 \nL 103.894597 115.354672 \nL 103.970693 115.265784 \nL 104.008741 115.287117 \nL 104.218004 115.358228 \nL 104.237028 115.319117 \nL 104.427267 115.283562 \nL 104.446291 115.368894 \nL 104.541411 115.347561 \nL 106.120396 115.30845 \nL 106.196491 115.226673 \nL 106.234539 115.251562 \nL 106.367707 115.304895 \nL 116.811837 115.408005 \nL 116.849884 115.418672 \nL 116.887932 115.358228 \nL 117.002076 115.304895 \nL 117.0211 115.34045 \nL 117.040124 115.386672 \nL 117.116219 115.319117 \nL 117.439626 115.304895 \nL 117.648889 115.322673 \nL 117.782056 115.276451 \nL 117.80108 115.315561 \nL 117.915224 115.322673 \nL 117.972295 115.287117 \nL 118.048391 115.40445 \nL 118.162535 115.272895 \nL 118.181559 115.30845 \nL 118.295702 115.361783 \nL 118.314726 115.319117 \nL 118.428869 115.255118 \nL 118.466917 115.294228 \nL 118.657156 115.354672 \nL 118.7713 115.312006 \nL 118.885443 115.436449 \nL 118.904467 115.425783 \nL 119.170802 115.354672 \nL 119.246898 115.411561 \nL 119.284946 115.365339 \nL 119.437137 115.304895 \nL 119.589328 115.315561 \nL 119.722496 115.240896 \nL 119.855663 115.336895 \nL 119.988831 115.244451 \nL 120.102974 115.425783 \nL 120.121998 115.383116 \nL 120.331261 115.326228 \nL 120.445405 115.390227 \nL 120.483452 115.326228 \nL 120.540524 115.422227 \nL 120.559548 115.365339 \nL 120.749787 115.333339 \nL 120.921002 115.344006 \nL 121.092218 115.287117 \nL 121.225385 115.37245 \nL 121.244409 115.326228 \nL 121.339529 115.383116 \nL 121.453672 115.315561 \nL 121.49172 115.351117 \nL 122.347796 115.301339 \nL 122.499988 115.361783 \nL 122.576083 115.319117 \nL 122.595107 115.347561 \nL 122.747298 115.418672 \nL 122.918514 115.365339 \nL 123.032657 115.361783 \nL 123.051681 115.34045 \nL 123.260944 115.265784 \nL 123.375088 115.333339 \nL 123.508255 115.290673 \nL 123.603375 115.255118 \nL 123.622399 115.347561 \nL 123.755566 115.301339 \nL 123.77459 115.365339 \nL 123.869709 115.297784 \nL 123.945805 115.365339 \nL 124.002877 115.333339 \nL 124.326283 115.344006 \nL 124.459451 115.297784 \nL 124.535547 115.40445 \nL 124.611642 115.304895 \nL 124.74481 115.258673 \nL 124.877977 115.322673 \nL 125.049192 115.312006 \nL 125.08724 115.262229 \nL 125.144312 115.336895 \nL 125.429671 115.408005 \nL 125.543814 115.297784 \nL 125.657958 115.393783 \nL 125.676982 115.365339 \nL 125.753077 115.265784 \nL 125.810149 115.301339 \nL 125.867221 115.333339 \nL 125.905269 115.262229 \nL 125.981364 115.301339 \nL 126.038436 115.397338 \nL 126.095508 115.368894 \nL 126.209651 115.272895 \nL 126.228675 115.333339 \nL 126.361843 115.297784 \nL 126.647201 115.344006 \nL 126.742321 115.383116 \nL 126.761345 115.336895 \nL 126.780369 115.301339 \nL 126.875488 115.358228 \nL 126.989632 115.376005 \nL 127.02768 115.322673 \nL 127.046703 115.397338 \nL 127.103775 115.379561 \nL 127.255967 115.37245 \nL 127.37011 115.304895 \nL 127.560349 115.333339 \nL 127.674493 115.287117 \nL 127.80766 115.312006 \nL 127.883756 115.297784 \nL 127.864732 115.347561 \nL 127.90278 115.351117 \nL 128.454473 115.358228 \nL 128.511545 115.322673 \nL 128.530569 115.276451 \nL 128.853976 115.37245 \nL 128.872999 115.415116 \nL 128.930071 115.365339 \nL 129.006167 115.23734 \nL 129.044215 115.329784 \nL 129.12031 115.358228 \nL 129.139334 115.294228 \nL 129.158358 115.244451 \nL 129.234454 115.315561 \nL 129.462741 115.37245 \nL 129.481765 115.436449 \nL 129.55786 115.326228 \nL 129.691028 115.390227 \nL 129.710052 115.368894 \nL 129.862243 115.30845 \nL 129.881267 115.336895 \nL 129.900291 115.393783 \nL 129.995411 115.347561 \nL 130.033458 115.26934 \nL 130.09053 115.351117 \nL 130.147602 115.400894 \nL 130.204674 115.365339 \nL 130.223698 115.248007 \nL 130.299793 115.383116 \nL 130.318817 115.280006 \nL 130.394913 115.379561 \nL 130.432961 115.283562 \nL 130.566128 115.383116 \nL 130.737343 115.276451 \nL 130.813439 115.361783 \nL 130.851487 115.326228 \nL 130.927582 115.276451 \nL 130.908558 115.368894 \nL 130.946606 115.290673 \nL 131.06075 115.440005 \nL 131.193917 115.258673 \nL 131.270013 115.411561 \nL 131.308061 115.390227 \nL 131.384156 115.219562 \nL 131.422204 115.312006 \nL 131.555372 115.301339 \nL 131.593419 115.26934 \nL 131.669515 115.468449 \nL 131.745611 115.258673 \nL 131.802683 115.272895 \nL 131.821706 115.376005 \nL 131.84073 115.244451 \nL 131.916826 115.30845 \nL 131.954874 115.20534 \nL 132.03097 115.379561 \nL 132.069017 115.411561 \nL 132.145113 115.233785 \nL 132.27828 115.393783 \nL 132.544615 115.34045 \nL 132.563639 115.223118 \nL 132.601687 115.365339 \nL 132.620711 115.276451 \nL 132.639735 115.450671 \nL 132.734854 115.37245 \nL 132.772902 115.290673 \nL 132.829974 115.415116 \nL 132.944118 115.326228 \nL 133.001189 115.233785 \nL 133.058261 115.326228 \nL 133.153381 115.262229 \nL 133.172405 115.233785 \nL 133.229476 115.315561 \nL 133.381668 115.312006 \nL 133.419715 115.34045 \nL 133.457763 115.301339 \nL 133.476787 115.415116 \nL 133.571907 115.383116 \nL 133.590931 115.26934 \nL 133.667026 115.315561 \nL 133.743122 115.464893 \nL 133.78117 115.450671 \nL 133.857266 115.248007 \nL 133.876289 115.472004 \nL 133.895313 115.344006 \nL 133.971409 115.486226 \nL 133.990433 115.294228 \nL 134.009457 115.461338 \nL 134.1236 115.201785 \nL 134.142624 115.386672 \nL 134.21872 115.144896 \nL 134.237744 115.283562 \nL 134.256768 115.13423 \nL 134.332863 115.40445 \nL 134.370911 115.418672 \nL 134.447007 115.322673 \nL 134.466031 115.436449 \nL 134.56115 115.411561 \nL 134.694318 115.248007 \nL 134.808461 115.379561 \nL 134.789437 115.208896 \nL 134.827485 115.312006 \nL 134.884557 115.240896 \nL 134.865533 115.40445 \nL 134.941629 115.312006 \nL 134.9987 115.436449 \nL 135.055772 115.368894 \nL 135.18894 115.280006 \nL 135.265035 115.37245 \nL 135.284059 115.216007 \nL 135.474298 115.411561 \nL 135.512346 115.379561 \nL 135.550394 115.322673 \nL 135.607466 115.379561 \nL 135.62649 115.50756 \nL 135.702585 115.290673 \nL 135.721609 115.408005 \nL 135.854777 115.333339 \nL 136.045016 115.400894 \nL 136.06404 115.219562 \nL 136.083064 115.422227 \nL 136.159159 115.23734 \nL 136.178183 115.468449 \nL 136.273303 115.376005 \nL 136.330375 115.397338 \nL 136.311351 115.287117 \nL 136.349399 115.365339 \nL 136.387446 115.397338 \nL 136.463542 115.176896 \nL 136.539638 115.347561 \nL 136.577686 115.304895 \nL 136.710853 115.212451 \nL 136.729877 115.248007 \nL 136.84402 115.44356 \nL 136.958164 115.262229 \nL 137.053283 115.383116 \nL 137.091331 115.368894 \nL 137.224499 115.208896 \nL 137.28157 115.283562 \nL 137.300594 115.379561 \nL 137.319618 115.233785 \nL 137.395714 115.336895 \nL 137.719121 115.34045 \nL 137.738144 115.230229 \nL 137.757168 115.37245 \nL 137.833264 115.294228 \nL 137.890336 115.44356 \nL 137.947408 115.40445 \nL 138.023503 115.344006 \nL 138.042527 115.468449 \nL 138.137647 115.386672 \nL 138.308862 115.34045 \nL 138.403982 115.294228 \nL 138.461053 115.365339 \nL 138.480077 115.141341 \nL 138.594221 115.397338 \nL 138.670316 115.255118 \nL 138.708364 115.351117 \nL 138.746412 115.383116 \nL 138.841532 115.329784 \nL 138.898603 115.425783 \nL 138.879579 115.280006 \nL 138.917627 115.326228 \nL 138.974699 115.176896 \nL 138.955675 115.450671 \nL 139.031771 115.251562 \nL 139.088842 115.425783 \nL 139.069819 115.184007 \nL 139.145914 115.329784 \nL 139.241034 115.272895 \nL 139.355177 115.393783 \nL 139.469321 115.304895 \nL 139.393225 115.415116 \nL 139.488345 115.312006 \nL 139.735656 115.201785 \nL 139.868823 115.489782 \nL 139.887847 115.479115 \nL 139.925895 115.600003 \nL 139.944919 115.390227 \nL 139.963943 115.592892 \nL 140.040038 115.368894 \nL 140.059062 115.425783 \nL 140.19223 115.276451 \nL 140.249301 115.223118 \nL 140.230277 115.297784 \nL 140.287349 115.280006 \nL 140.515636 115.440005 \nL 140.648804 115.226673 \nL 140.667828 115.37245 \nL 140.743923 115.173341 \nL 140.762947 115.290673 \nL 140.781971 115.180452 \nL 140.877091 115.251562 \nL 141.029282 115.432894 \nL 140.915138 115.219562 \nL 141.048306 115.393783 \nL 141.06733 115.429338 \nL 141.124402 115.312006 \nL 141.143425 115.383116 \nL 141.257569 115.20534 \nL 141.276593 115.351117 \nL 141.352689 115.112897 \nL 141.371712 115.240896 \nL 141.390736 115.184007 \nL 141.428784 115.336895 \nL 141.447808 115.287117 \nL 141.485856 115.240896 \nL 141.638047 115.422227 \nL 141.676095 115.553781 \nL 141.752191 115.354672 \nL 141.771215 115.528893 \nL 141.790239 115.312006 \nL 141.866334 115.436449 \nL 141.904382 115.47556 \nL 141.980478 115.26934 \nL 142.075597 115.347561 \nL 142.056573 115.240896 \nL 142.094621 115.283562 \nL 142.132669 115.351117 \nL 142.151693 115.248007 \nL 142.265837 115.450671 \nL 142.418028 115.326228 \nL 142.437052 115.461338 \nL 142.513147 115.301339 \nL 142.532171 115.361783 \nL 142.646315 115.244451 \nL 142.760458 115.379561 \nL 142.81753 115.319117 \nL 142.798506 115.457782 \nL 142.836554 115.450671 \nL 143.159961 115.40445 \nL 143.312152 115.208896 \nL 143.331176 115.376005 \nL 143.3502 115.169785 \nL 143.426295 115.336895 \nL 143.445319 115.116452 \nL 143.540439 115.191118 \nL 143.673606 115.47556 \nL 143.69263 115.440005 \nL 143.806774 115.418672 \nL 143.844822 115.354672 \nL 143.882869 115.422227 \nL 144.035061 115.152008 \nL 144.073109 115.137785 \nL 144.206276 115.368894 \nL 144.2253 115.358228 \nL 144.244324 115.482671 \nL 144.339443 115.450671 \nL 144.415539 115.400894 \nL 144.453587 115.450671 \nL 144.529683 115.287117 \nL 144.605778 115.461338 \nL 144.624802 115.26934 \nL 144.643826 115.454227 \nL 144.66285 115.283562 \nL 144.738946 115.553781 \nL 144.872113 115.429338 \nL 145.119424 114.949343 \nL 145.233567 115.016898 \nL 145.252591 114.920899 \nL 145.328687 115.009787 \nL 145.366735 115.116452 \nL 145.423807 114.960009 \nL 145.480878 114.771567 \nL 145.53795 114.832011 \nL 145.880381 117.605317 \nL 145.9755 117.249765 \nL 146.184763 115.432894 \nL 146.355979 114.14224 \nL 146.41305 114.753789 \nL 146.50817 115.866667 \nL 146.565242 115.845334 \nL 146.622313 115.525337 \nL 146.679385 115.617781 \nL 146.736457 115.987555 \nL 146.717433 115.592892 \nL 146.793529 115.895111 \nL 146.94572 114.636457 \nL 146.964744 114.693345 \nL 146.983768 114.597346 \nL 147.021816 114.945787 \nL 147.154983 115.767113 \nL 147.174007 115.674669 \nL 147.307174 118.259533 \nL 147.345222 118.063979 \nL 147.459366 113.082695 \nL 147.649605 107.009865 \nL 147.668629 107.009865 \nL 147.763748 109.722727 \nL 148.125203 124.506582 \nL 148.182274 125.303019 \nL 148.220322 124.73058 \nL 148.391538 119.191079 \nL 148.448609 119.276412 \nL 148.543729 117.964424 \nL 148.581777 117.235543 \nL 148.638848 118.003535 \nL 148.714944 120.211513 \nL 148.772016 119.045303 \nL 148.886159 110.106724 \nL 149.057375 105.185883 \nL 149.13347 104.208115 \nL 149.152494 104.627666 \nL 149.456877 118.007091 \nL 149.57102 132.086952 \nL 149.647116 127.144779 \nL 149.894427 87.166504 \nL 149.913451 88.034051 \nL 149.970523 86.89984 \nL 149.989547 88.023385 \nL 150.408073 148.648568 \nL 150.465144 144.278833 \nL 150.807575 106.29165 \nL 150.826599 106.899644 \nL 150.940742 118.924415 \nL 151.035862 129.03276 \nL 151.092934 126.0639 \nL 151.454388 97.825955 \nL 151.51146 101.761917 \nL 151.796819 121.196393 \nL 151.834866 119.727963 \nL 151.891938 118.522641 \nL 152.101201 103.472122 \nL 152.120225 103.692564 \nL 152.253393 110.69694 \nL 152.272416 110.544053 \nL 152.29144 109.708505 \nL 152.310464 110.885383 \nL 152.519727 142.934846 \nL 152.557775 137.423789 \nL 152.786062 82.458995 \nL 152.805086 85.093636 \nL 152.881182 83.305209 \nL 153.090445 135.233588 \nL 153.204588 149.612114 \nL 153.242636 147.457468 \nL 153.26166 147.688577 \nL 153.299708 149.644114 \nL 153.337756 145.285045 \nL 153.413851 129.768753 \nL 153.547019 101.44192 \nL 153.604091 101.865027 \nL 153.737258 105.47388 \nL 153.813354 113.061361 \nL 153.946521 137.903784 \nL 153.984569 135.542919 \nL 154.117736 116.207997 \nL 154.365047 95.731754 \nL 154.384071 97.264183 \nL 154.612358 117.879092 \nL 154.707478 117.025767 \nL 154.745526 117.274653 \nL 154.802597 115.667558 \nL 154.935765 104.862331 \nL 155.01186 107.952078 \nL 155.126004 115.760002 \nL 155.164052 114.188461 \nL 155.183076 113.804465 \nL 155.2021 114.519125 \nL 155.316243 138.646888 \nL 155.354291 147.087694 \nL 155.430387 139.784655 \nL 155.658674 73.278641 \nL 155.696721 81.836779 \nL 156.096224 152.883193 \nL 155.753793 80.962121 \nL 156.134271 147.429024 \nL 156.172319 148.328571 \nL 156.191343 147.81302 \nL 156.324511 114.604457 \nL 156.41963 102.771685 \nL 156.438654 105.896987 \nL 156.571822 124.826579 \nL 156.609869 123.148374 \nL 156.685965 118.757305 \nL 156.704989 122.142161 \nL 156.800109 134.362486 \nL 156.85718 128.574098 \nL 157.066443 97.843733 \nL 157.104491 98.327284 \nL 157.161563 92.748672 \nL 157.199611 89.609147 \nL 157.256683 93.609108 \nL 157.408874 120.499511 \nL 157.48497 114.686234 \nL 157.561065 110.298722 \nL 157.599113 111.920039 \nL 157.637161 114.11024 \nL 157.694233 111.454266 \nL 157.789352 102.746796 \nL 157.846424 106.423204 \nL 158.207878 137.050459 \nL 158.26495 159.96579 \nL 158.322022 150.003221 \nL 158.436165 92.314898 \nL 158.569333 64.116064 \nL 158.588357 66.149822 \nL 158.835668 144.396165 \nL 158.911763 163.816419 \nL 158.949811 149.288562 \nL 159.178098 112.524478 \nL 159.254194 88.890932 \nL 159.311265 93.154001 \nL 159.444433 148.239683 \nL 159.520529 137.423789 \nL 159.5776 124.222141 \nL 159.634672 131.820288 \nL 159.691744 135.091367 \nL 159.710768 131.148295 \nL 159.843935 88.663379 \nL 159.920031 100.485485 \nL 159.977103 109.978725 \nL 160.034174 105.406325 \nL 160.11027 90.007365 \nL 160.167342 98.046398 \nL 160.262461 124.855023 \nL 160.338557 113.598245 \nL 160.414653 103.205458 \nL 160.471724 107.486305 \nL 160.528796 119.173301 \nL 160.604892 112.325369 \nL 160.680987 94.689986 \nL 160.738059 100.737927 \nL 160.871227 120.961728 \nL 160.890251 117.683538 \nL 160.947322 107.546749 \nL 161.023418 111.507599 \nL 161.156585 175.798524 \nL 161.232681 146.760586 \nL 161.499016 52.286847 \nL 161.556088 77.502599 \nL 161.594135 78.811031 \nL 161.727303 166.667947 \nL 161.784375 157.256483 \nL 161.803399 159.912457 \nL 161.822422 156.879598 \nL 162.012662 119.141302 \nL 162.126805 76.681274 \nL 162.183877 94.060659 \nL 162.336068 162.984427 \nL 162.39314 147.333025 \nL 162.583379 117.086211 \nL 162.678499 87.461613 \nL 162.754594 96.18686 \nL 162.83069 131.18385 \nL 162.887762 120.424845 \nL 162.982881 86.658065 \nL 163.039953 96.332637 \nL 163.135073 123.052374 \nL 163.192144 117.541317 \nL 163.249216 99.429495 \nL 163.306288 105.104106 \nL 163.36336 120.225736 \nL 163.420431 111.955594 \nL 163.458479 106.096096 \nL 163.515551 92.585118 \nL 163.572623 102.049914 \nL 163.667742 128.442544 \nL 163.743838 113.566245 \nL 163.781886 107.635637 \nL 163.857981 111.976928 \nL 164.067245 184.402884 \nL 164.105292 161.164001 \nL 164.295532 42.896716 \nL 164.333579 51.291301 \nL 164.390651 45.968686 \nL 164.504795 113.082695 \nL 164.618938 166.856389 \nL 164.656986 156.488491 \nL 164.809177 96.919298 \nL 164.942345 110.216945 \nL 165.189656 162.667986 \nL 165.227703 153.011192 \nL 165.379895 97.050852 \nL 165.417943 104.222337 \nL 165.627206 126.298565 \nL 165.64623 125.27813 \nL 165.665254 130.067417 \nL 165.703301 137.25668 \nL 165.741349 124.474583 \nL 165.855493 79.682133 \nL 165.912564 90.24203 \nL 166.007684 125.65146 \nL 166.08378 118.703973 \nL 166.178899 103.081015 \nL 166.235971 104.805442 \nL 166.331091 92.39312 \nL 166.388162 96.979741 \nL 166.502306 120.527955 \nL 166.540354 117.683538 \nL 166.635473 96.172638 \nL 166.692545 109.619617 \nL 166.901808 148.157906 \nL 166.95888 207.460435 \nL 166.996928 150.899212 \nL 167.168143 39.735859 \nL 167.206191 59.03878 \nL 167.453502 183.115785 \nL 167.263262 56.660137 \nL 167.472526 179.855373 \nL 167.510573 158.920467 \nL 167.643741 80.723901 \nL 167.662765 88.794933 \nL 167.814956 115.386672 \nL 167.948123 155.891163 \nL 167.986171 144.527719 \nL 168.081291 119.336855 \nL 168.138363 124.211474 \nL 168.27153 105.95032 \nL 168.290554 111.557376 \nL 168.385674 127.532331 \nL 168.423721 125.043466 \nL 168.518841 101.210811 \nL 168.575913 113.306692 \nL 168.594937 113.22136 \nL 168.728104 92.1229 \nL 168.747128 96.08375 \nL 168.861271 137.402456 \nL 168.899319 123.621258 \nL 168.994439 92.322009 \nL 169.089558 96.058862 \nL 169.108582 96.314859 \nL 169.127606 96.044639 \nL 169.165654 94.842873 \nL 169.184678 97.082851 \nL 169.222726 95.269536 \nL 169.24175 99.706826 \nL 169.298822 131.340293 \nL 169.374917 120.236402 \nL 169.431989 102.142357 \nL 169.508085 109.793838 \nL 169.527109 110.440943 \nL 169.58418 125.551906 \nL 169.641252 119.543076 \nL 169.660276 120.051515 \nL 169.698324 118.995525 \nL 169.736372 134.622039 \nL 169.793443 208.985754 \nL 169.831491 158.255585 \nL 169.945635 61.758754 \nL 170.002706 66.693816 \nL 170.02173 61.687643 \nL 170.040754 69.502678 \nL 170.269041 189.949496 \nL 170.11685 53.172171 \nL 170.288065 189.561944 \nL 170.478304 84.243866 \nL 170.5544 100.86237 \nL 170.573424 100.638372 \nL 170.687567 157.779145 \nL 170.706591 164.687522 \nL 170.744639 151.073433 \nL 170.839759 105.530769 \nL 170.915854 117.096877 \nL 170.953902 124.687914 \nL 170.99195 110.472942 \nL 171.010974 108.951179 \nL 171.029998 113.964464 \nL 171.163165 154.476066 \nL 171.201213 140.591758 \nL 171.353404 87.308725 \nL 171.372428 100.289931 \nL 171.410476 124.136808 \nL 171.486572 114.867566 \nL 171.543644 105.203661 \nL 171.562668 109.968058 \nL 171.657787 121.854164 \nL 171.676811 116.488883 \nL 171.733883 89.708702 \nL 171.790955 100.993924 \nL 171.86705 120.986617 \nL 171.924122 113.338692 \nL 171.981194 105.541435 \nL 172.000218 108.798292 \nL 172.038265 122.657712 \nL 172.095337 107.9663 \nL 172.152409 88.745156 \nL 172.209481 101.740584 \nL 172.418744 132.335839 \nL 172.475816 120.922618 \nL 172.494839 117.509318 \nL 172.532887 122.526157 \nL 172.608983 202.74937 \nL 172.647031 143.091289 \nL 172.74215 69.051127 \nL 172.780198 83.422541 \nL 172.818246 81.947 \nL 172.93239 47.831779 \nL 172.951413 63.074296 \nL 173.027509 174.881199 \nL 173.103605 158.419139 \nL 173.312868 77.484822 \nL 173.350916 88.197605 \nL 173.484083 182.970009 \nL 173.541155 134.323375 \nL 173.655298 102.313022 \nL 173.674322 107.962745 \nL 173.731394 117.519984 \nL 173.769442 107.89519 \nL 173.788466 103.436567 \nL 173.826514 115.162674 \nL 173.940657 155.055616 \nL 173.959681 150.390773 \nL 174.054801 98.871278 \nL 174.111872 116.648882 \nL 174.130896 117.86487 \nL 174.187968 106.280983 \nL 174.24504 109.360064 \nL 174.264064 109.758283 \nL 174.340159 132.346506 \nL 174.378207 125.583905 \nL 174.435279 91.977124 \nL 174.530398 95.745976 \nL 174.568446 102.540576 \nL 174.739662 133.086054 \nL 174.758685 131.788289 \nL 174.948925 88.382492 \nL 174.967949 97.509514 \nL 175.044044 93.90066 \nL 175.12014 112.812475 \nL 175.177212 122.995486 \nL 175.234283 119.70663 \nL 175.272331 115.824001 \nL 175.291355 116.015999 \nL 175.348427 174.26965 \nL 175.386475 214.756364 \nL 175.424523 151.613872 \nL 175.500618 77.104381 \nL 175.55769 95.767309 \nL 175.576714 99.059721 \nL 175.633786 41.04429 \nL 175.709881 54.814822 \nL 175.785977 175.368306 \nL 175.881097 140.997087 \nL 176.09036 62.679633 \nL 176.128407 87.813609 \nL 176.242551 172.87233 \nL 176.299623 143.596173 \nL 176.356694 109.189399 \nL 176.413766 122.007051 \nL 176.43279 121.836386 \nL 176.508886 101.697917 \nL 176.546934 111.191158 \nL 176.642053 150.650326 \nL 176.718149 130.938519 \nL 176.87034 100.073044 \nL 176.889364 101.281921 \nL 176.908388 97.648179 \nL 176.946436 105.19655 \nL 177.079603 142.714404 \nL 177.117651 126.447897 \nL 177.193747 98.512171 \nL 177.269842 101.655251 \nL 177.345938 89.655369 \nL 177.383986 98.106841 \nL 177.40301 98.444616 \nL 177.574225 124.403472 \nL 177.726416 101.239255 \nL 177.802512 90.231363 \nL 177.84056 99.237497 \nL 177.916656 123.823922 \nL 177.992751 113.726244 \nL 178.049823 101.289032 \nL 178.068847 112.247147 \nL 178.163967 200.758279 \nL 178.202014 142.493962 \nL 178.240062 75.397731 \nL 178.316158 96.858854 \nL 178.335182 104.304114 \nL 178.37323 91.738904 \nL 178.430301 40.663849 \nL 178.487373 77.776374 \nL 178.563469 161.217333 \nL 178.639564 130.824743 \nL 178.658588 126.341231 \nL 178.696636 139.741989 \nL 178.734684 143.397064 \nL 178.753708 135.966026 \nL 178.867851 60.709875 \nL 178.905899 103.792119 \nL 178.962971 148.463681 \nL 179.039067 136.534909 \nL 179.096138 123.148374 \nL 179.134186 141.146419 \nL 179.15321 149.573003 \nL 179.191258 127.944771 \nL 179.24833 90.832246 \nL 179.305401 120.165292 \nL 179.362473 139.030884 \nL 179.419545 134.408707 \nL 179.476617 115.827556 \nL 179.514665 133.871824 \nL 179.552712 136.794462 \nL 179.571736 130.554523 \nL 179.68588 88.649156 \nL 179.723928 99.15572 \nL 179.819047 133.203386 \nL 179.914167 122.391048 \nL 180.104406 90.533582 \nL 180.12343 100.798371 \nL 180.180502 111.699597 \nL 180.199526 99.674826 \nL 180.218549 98.551282 \nL 180.237573 87.642944 \nL 180.294645 105.81521 \nL 180.351717 129.224758 \nL 180.408789 120.535066 \nL 180.46586 105.6801 \nL 180.522932 118.504864 \nL 180.541956 119.425743 \nL 180.56098 116.986656 \nL 180.637076 92.233121 \nL 180.694147 104.051672 \nL 180.713171 103.756564 \nL 180.846339 125.99279 \nL 180.90341 210.080854 \nL 180.941458 148.442348 \nL 180.979506 85.690963 \nL 181.055602 112.858697 \nL 181.09365 100.631261 \nL 181.150721 30.015065 \nL 181.207793 62.252971 \nL 181.283889 166.486615 \nL 181.379008 119.500409 \nL 181.455104 159.713348 \nL 181.493152 131.859399 \nL 181.588271 65.332052 \nL 181.626319 102.931683 \nL 181.683391 143.226399 \nL 181.740463 125.121687 \nL 181.759487 125.061244 \nL 181.892654 138.163337 \nL 181.96875 103.376123 \nL 182.025822 121.473723 \nL 182.063869 130.12075 \nL 182.120941 119.813295 \nL 182.235085 142.049521 \nL 182.273132 134.80337 \nL 182.349228 97.146851 \nL 182.387276 102.423244 \nL 182.444348 125.765237 \nL 182.501419 109.427619 \nL 182.520443 100.425041 \nL 182.577515 121.427502 \nL 182.596539 138.746443 \nL 182.672635 113.722688 \nL 182.710682 103.820563 \nL 182.729706 100.307709 \nL 182.767754 107.820524 \nL 182.786778 115.962666 \nL 182.84385 98.931722 \nL 182.900922 90.025143 \nL 182.919946 100.065933 \nL 182.938969 99.635715 \nL 183.072137 121.107505 \nL 183.148233 106.76809 \nL 183.18628 115.173341 \nL 183.205304 116.079998 \nL 183.224328 114.650679 \nL 183.262376 92.386009 \nL 183.319448 105.864988 \nL 183.37652 125.975012 \nL 183.414567 104.780554 \nL 183.509687 90.000254 \nL 183.528711 103.130792 \nL 183.62383 193.334352 \nL 183.661878 119.46841 \nL 183.699926 74.853736 \nL 183.756998 141.932189 \nL 183.871141 23.768015 \nL 183.928213 86.857174 \nL 184.004309 145.17838 \nL 184.042357 105.040107 \nL 184.061381 89.854478 \nL 184.099428 124.591915 \nL 184.1565 167.571049 \nL 184.194548 134.444263 \nL 184.25162 84.681195 \nL 184.308691 98.142397 \nL 184.365763 142.255742 \nL 184.441859 117.487985 \nL 184.536978 149.48056 \nL 184.575026 123.15904 \nL 184.651122 98.252618 \nL 184.68917 116.60266 \nL 184.727218 141.462861 \nL 184.784289 109.075623 \nL 184.803313 109.200066 \nL 184.822337 100.634817 \nL 184.860385 122.938598 \nL 184.898433 148.421014 \nL 184.955505 117.605317 \nL 184.974529 121.640833 \nL 184.993552 109.36362 \nL 185.012576 111.418711 \nL 185.0316 106.849867 \nL 185.050624 112.311147 \nL 185.107696 136.072691 \nL 185.145744 107.873857 \nL 185.164768 108.624072 \nL 185.183792 93.01178 \nL 185.240863 121.950163 \nL 185.297935 135.340254 \nL 185.335983 122.831932 \nL 185.374031 105.064995 \nL 185.431103 124.31814 \nL 185.450126 132.979388 \nL 185.507198 109.882726 \nL 185.56427 74.949735 \nL 185.602318 107.105864 \nL 185.640366 119.816851 \nL 185.697437 102.931683 \nL 185.716461 96.300637 \nL 185.773533 113.744021 \nL 185.868653 125.100354 \nL 185.887677 115.20534 \nL 186.020844 92.442897 \nL 186.039868 96.727299 \nL 186.077916 112.065816 \nL 186.154011 102.714796 \nL 186.173035 98.220618 \nL 186.211083 110.174279 \nL 186.306203 170.337244 \nL 186.325227 156.918709 \nL 186.382298 69.790675 \nL 186.43937 132.257617 \nL 186.53449 50.829083 \nL 186.553514 32.1306 \nL 186.591561 82.519439 \nL 186.629609 122.391048 \nL 186.705705 121.324391 \nL 186.743753 102.977905 \nL 186.781801 135.781138 \nL 186.819848 160.367564 \nL 186.857896 135.656695 \nL 186.933992 81.065231 \nL 186.97204 113.765354 \nL 187.048135 127.980326 \nL 187.086183 125.128799 \nL 187.105207 120.442622 \nL 187.124231 131.756289 \nL 187.181303 160.673339 \nL 187.219351 133.007832 \nL 187.257398 102.156579 \nL 187.333494 121.295947 \nL 187.352518 128.147436 \nL 187.40959 120.360845 \nL 187.466662 101.221478 \nL 187.504709 120.126181 \nL 187.561781 144.275277 \nL 187.599829 121.640833 \nL 187.618853 121.047061 \nL 187.637877 102.608131 \nL 187.694949 126.849671 \nL 187.713972 125.089688 \nL 187.732996 125.534128 \nL 187.828116 95.852641 \nL 187.866164 111.767152 \nL 187.942259 132.012287 \nL 187.961283 125.31013 \nL 187.999331 108.570739 \nL 188.075427 112.595588 \nL 188.094451 113.072028 \nL 188.113475 111.372489 \nL 188.18957 124.325251 \nL 188.227618 118.942193 \nL 188.360786 94.98865 \nL 188.37981 97.633957 \nL 188.436881 110.053391 \nL 188.493953 108.520961 \nL 188.512977 104.620555 \nL 188.532001 109.288954 \nL 188.589073 126.583006 \nL 188.62712 105.832988 \nL 188.703216 116.638215 \nL 188.741264 113.943131 \nL 188.855407 93.854439 \nL 188.969551 161.604885 \nL 189.007599 152.083201 \nL 189.045647 93.662441 \nL 189.140766 107.589415 \nL 189.235886 31.47994 \nL 189.273934 89.772701 \nL 189.311981 116.965323 \nL 189.407101 116.183109 \nL 189.483197 160.463563 \nL 189.540268 128.908317 \nL 189.711484 87.68561 \nL 189.825627 157.199595 \nL 189.901723 129.608755 \nL 189.920747 127.123446 \nL 189.939771 128.798096 \nL 190.015866 146.490367 \nL 190.03489 120.623954 \nL 190.091962 87.554056 \nL 190.13001 114.028463 \nL 190.187082 132.534948 \nL 190.225129 112.727142 \nL 190.244153 107.130753 \nL 190.301225 121.943052 \nL 190.320249 135.489586 \nL 190.396345 117.007989 \nL 190.434392 105.143217 \nL 190.491464 115.639114 \nL 190.510488 122.494158 \nL 190.56756 103.806341 \nL 190.586584 104.058783 \nL 190.662679 133.43805 \nL 190.719751 113.76891 \nL 190.738775 105.040107 \nL 190.795847 115.024009 \nL 190.852919 126.529674 \nL 190.890966 116.385773 \nL 190.929014 98.881945 \nL 190.986086 116.609771 \nL 191.00511 122.639934 \nL 191.062182 117.423985 \nL 191.138277 96.243749 \nL 191.176325 105.388548 \nL 191.195349 115.248007 \nL 191.271445 101.289032 \nL 191.34754 119.980405 \nL 191.385588 112.887141 \nL 191.404612 102.515687 \nL 191.480708 115.006231 \nL 191.53778 134.305597 \nL 191.632899 128.488766 \nL 191.689971 102.458799 \nL 191.728019 124.321695 \nL 191.747043 128.126102 \nL 191.766067 111.728041 \nL 191.861186 53.993496 \nL 191.88021 70.004006 \nL 191.937282 103.539677 \nL 191.994354 89.811812 \nL 192.032401 103.440122 \nL 192.108497 138.568667 \nL 192.184593 133.356273 \nL 192.355808 102.928127 \nL 192.488975 121.256837 \nL 192.565071 144.869049 \nL 192.660191 139.517991 \nL 192.793358 121.24617 \nL 192.812382 123.322594 \nL 192.831406 115.333339 \nL 192.869454 108.360963 \nL 192.907502 125.875458 \nL 192.945549 129.701198 \nL 193.021645 110.90316 \nL 193.059693 111.016937 \nL 193.097741 119.415077 \nL 193.135789 118.1742 \nL 193.154813 104.915664 \nL 193.249932 105.438325 \nL 193.364076 126.750116 \nL 193.3831 123.50037 \nL 193.402123 125.608794 \nL 193.440171 118.312865 \nL 193.459195 120.165292 \nL 193.668458 93.882883 \nL 193.744554 123.838145 \nL 193.801626 122.295049 \nL 193.953817 101.939693 \nL 193.972841 104.780554 \nL 194.144056 128.72343 \nL 194.16308 125.125243 \nL 194.201128 135.706473 \nL 194.239176 152.72675 \nL 194.277224 124.225696 \nL 194.315271 93.463331 \nL 194.410391 98.636614 \nL 194.429415 95.575311 \nL 194.467463 63.426293 \nL 194.524534 105.580546 \nL 194.581606 91.141576 \nL 194.60063 88.211827 \nL 194.714774 124.072809 \nL 194.733798 118.021313 \nL 194.790869 104.929886 \nL 194.847941 114.529791 \nL 194.885989 128.613209 \nL 194.924037 111.909373 \nL 194.943061 105.502324 \nL 194.981108 121.541278 \nL 195.019156 132.915389 \nL 195.114276 129.619421 \nL 195.171348 136.57402 \nL 195.190372 128.570543 \nL 195.247443 117.573317 \nL 195.285491 124.581248 \nL 195.323539 133.381162 \nL 195.361587 131.784733 \nL 195.418659 115.68178 \nL 195.456706 129.914529 \nL 195.513778 132.399838 \nL 195.627922 118.664862 \nL 195.646946 121.445279 \nL 195.799137 103.699675 \nL 196.046448 122.618601 \nL 196.065472 121.5875 \nL 196.236687 103.137903 \nL 196.255711 96.453524 \nL 196.312783 111.532487 \nL 196.331807 116.787547 \nL 196.388878 106.540536 \nL 196.407902 107.240974 \nL 196.503022 126.1279 \nL 196.54107 112.517367 \nL 196.579117 101.836583 \nL 196.636189 108.119188 \nL 196.731309 107.436528 \nL 196.807404 144.069057 \nL 196.845452 110.199167 \nL 196.940572 120.90484 \nL 196.997644 89.957588 \nL 197.016668 73.07242 \nL 197.092763 95.820642 \nL 197.111787 81.328339 \nL 197.149835 73.843968 \nL 197.168859 86.924729 \nL 197.340074 131.823844 \nL 197.359098 132.54917 \nL 197.378122 129.292313 \nL 197.397146 130.166971 \nL 197.511289 100.691705 \nL 197.568361 106.074763 \nL 197.625433 97.399293 \nL 197.644457 103.575232 \nL 197.834696 141.583748 \nL 197.85372 146.27348 \nL 197.891768 130.383858 \nL 198.062983 113.470246 \nL 198.120055 120.599065 \nL 198.158103 130.87452 \nL 198.234198 130.202527 \nL 198.367366 111.61782 \nL 198.386389 112.865808 \nL 198.405413 113.175138 \nL 198.424437 115.710224 \nL 198.443461 112.858697 \nL 198.481509 112.990251 \nL 198.538581 103.770786 \nL 198.576629 114.135129 \nL 198.614676 122.206161 \nL 198.671748 110.501386 \nL 198.709796 101.537919 \nL 198.766868 110.000058 \nL 198.861987 114.807122 \nL 198.900035 113.921797 \nL 198.919059 108.684515 \nL 198.995155 117.509318 \nL 199.185394 100.641928 \nL 199.337585 134.62915 \nL 199.356609 131.258516 \nL 199.413681 103.408123 \nL 199.489777 113.960908 \nL 199.584896 83.838537 \nL 199.622944 100.343264 \nL 199.641968 106.906755 \nL 199.69904 98.074842 \nL 199.737088 102.771685 \nL 199.946351 122.671934 \nL 199.965375 118.671973 \nL 200.022446 129.014983 \nL 200.04147 130.934964 \nL 200.060494 124.289696 \nL 200.079518 125.20702 \nL 200.098542 123.621258 \nL 200.117566 128.133214 \nL 200.13659 131.507403 \nL 200.174638 121.583944 \nL 200.307805 103.159236 \nL 200.345853 106.458759 \nL 200.498044 131.148295 \nL 200.536092 144.502831 \nL 200.593164 130.888742 \nL 200.821451 105.125439 \nL 200.878523 110.508498 \nL 200.935594 126.757227 \nL 200.992666 117.288875 \nL 201.01169 116.335996 \nL 201.030714 120.239958 \nL 201.068762 129.260314 \nL 201.125833 120.115514 \nL 201.259001 106.97431 \nL 201.278025 108.389407 \nL 201.316073 103.813452 \nL 201.335097 107.358306 \nL 201.430216 102.241912 \nL 201.44924 102.508576 \nL 201.620455 122.149272 \nL 201.715575 108.542295 \nL 201.753623 112.890696 \nL 201.791671 119.2693 \nL 201.829718 115.703113 \nL 201.867766 105.939653 \nL 201.924838 120.15107 \nL 201.962886 114.362682 \nL 202.019958 122.366159 \nL 202.038981 116.186664 \nL 202.077029 121.491501 \nL 202.096053 114.135129 \nL 202.248245 96.588634 \nL 202.305316 91.422463 \nL 202.457508 125.544794 \nL 202.476531 123.415038 \nL 202.495555 130.12075 \nL 202.590675 124.574137 \nL 202.609699 122.27016 \nL 202.647747 125.438129 \nL 202.666771 128.968761 \nL 202.704818 118.295088 \nL 202.723842 117.605317 \nL 202.742866 106.032097 \nL 202.818962 120.631065 \nL 202.895058 109.843615 \nL 202.952129 112.919141 \nL 203.009201 123.713701 \nL 203.066273 117.928869 \nL 203.085297 116.19022 \nL 203.104321 120.392845 \nL 203.123345 116.791103 \nL 203.19944 131.016741 \nL 203.256512 124.9368 \nL 203.275536 128.335878 \nL 203.332608 123.077263 \nL 203.484799 107.991189 \nL 203.541871 112.289813 \nL 203.560895 120.236402 \nL 203.656014 117.807981 \nL 203.675038 117.953758 \nL 203.73211 128.044325 \nL 203.770158 119.703074 \nL 203.941373 103.603676 \nL 203.865277 121.00795 \nL 203.960397 104.318336 \nL 203.979421 104.698777 \nL 204.07454 104.489001 \nL 204.093564 108.37163 \nL 204.16966 104.233004 \nL 204.131612 110.977826 \nL 204.207708 105.605435 \nL 204.378923 124.559915 \nL 204.416971 112.823141 \nL 204.474043 131.553624 \nL 204.60721 107.432972 \nL 204.626234 108.023189 \nL 204.645258 116.57066 \nL 204.70233 97.21085 \nL 204.721354 97.907732 \nL 204.759401 107.130753 \nL 204.816473 100.396597 \nL 204.854521 98.26684 \nL 205.006712 116.652437 \nL 205.177928 131.35096 \nL 205.196952 131.301182 \nL 205.368167 116.02311 \nL 205.425239 110.167168 \nL 205.463286 114.423126 \nL 205.501334 117.466651 \nL 205.539382 111.315601 \nL 205.558406 110.291611 \nL 205.57743 111.415155 \nL 205.729621 130.714522 \nL 205.748645 129.797197 \nL 205.767669 131.322516 \nL 205.786693 130.117194 \nL 205.957908 109.132511 \nL 206.034004 118.689751 \nL 206.091076 114.209795 \nL 206.1101 106.661424 \nL 206.167171 116.84088 \nL 206.186195 121.342169 \nL 206.262291 115.983999 \nL 206.281315 116.250663 \nL 206.376434 112.492478 \nL 206.414482 112.620477 \nL 206.433506 117.303098 \nL 206.490578 106.597425 \nL 206.509602 103.315679 \nL 206.566673 108.844514 \nL 206.585697 113.008029 \nL 206.642769 107.184086 \nL 206.661793 104.442779 \nL 206.737889 108.560072 \nL 206.871056 116.965323 \nL 206.947152 107.852524 \nL 206.9852 113.946686 \nL 207.023247 119.226634 \nL 207.061295 108.652516 \nL 207.080319 113.214249 \nL 207.099343 107.738747 \nL 207.137391 113.555579 \nL 207.156415 112.997362 \nL 207.175439 119.272856 \nL 207.232511 107.098753 \nL 207.365678 102.341467 \nL 207.42275 113.921797 \nL 207.479821 104.329003 \nL 207.498845 103.020571 \nL 207.517869 106.369871 \nL 207.708108 130.838965 \nL 207.727132 133.665604 \nL 207.784204 129.214092 \nL 207.955419 114.138684 \nL 208.012491 120.115514 \nL 208.069563 115.639114 \nL 208.088587 115.34045 \nL 208.164682 125.089688 \nL 208.20273 118.337754 \nL 208.240778 115.155563 \nL 208.278826 118.714639 \nL 208.29785 121.036394 \nL 208.354922 116.577771 \nL 208.373946 117.45954 \nL 208.392969 116.439106 \nL 208.411993 118.817749 \nL 208.488089 116.791103 \nL 208.526137 122.721711 \nL 208.64028 106.192095 \nL 208.659304 110.554719 \nL 208.716376 115.756446 \nL 208.754424 107.848968 \nL 208.773448 111.987594 \nL 208.963687 122.344826 \nL 209.039783 106.099652 \nL 209.115878 109.843615 \nL 209.191974 104.414335 \nL 209.210998 105.836543 \nL 209.420261 127.916327 \nL 209.496357 115.71378 \nL 209.553428 116.129776 \nL 209.629524 97.015297 \nL 209.724644 100.407263 \nL 209.781715 95.859752 \nL 209.933907 117.303098 \nL 209.952931 114.035574 \nL 210.029026 116.826658 \nL 210.04805 117.324431 \nL 210.105122 130.686077 \nL 210.181218 127.542997 \nL 210.238289 134.0496 \nL 210.295361 129.562533 \nL 210.314385 129.338535 \nL 210.447552 117.178654 \nL 210.504624 118.263088 \nL 210.58072 113.274693 \nL 210.618768 117.495096 \nL 210.656815 121.512834 \nL 210.694863 114.853344 \nL 210.713887 112.204481 \nL 210.751935 120.80173 \nL 210.789983 127.109224 \nL 210.847055 119.180412 \nL 210.866079 119.397299 \nL 211.094366 104.371669 \nL 211.132413 105.232105 \nL 211.189485 111.00627 \nL 211.265581 110.362721 \nL 211.303629 116.399995 \nL 211.3607 111.653375 \nL 211.379724 110.302277 \nL 211.398748 113.978686 \nL 211.436796 113.882687 \nL 211.45582 114.576013 \nL 211.474844 110.846272 \nL 211.55094 115.511115 \nL 211.722155 118.792861 \nL 211.627035 115.347561 \nL 211.760203 117.86487 \nL 211.779227 114.106684 \nL 211.855322 118.913748 \nL 211.874346 114.124462 \nL 211.89337 114.24535 \nL 211.931418 111.664042 \nL 211.950442 116.360885 \nL 211.969466 113.210693 \nL 211.98849 115.845334 \nL 212.064585 111.944928 \nL 212.33092 102.02147 \nL 212.102633 112.769809 \nL 212.368968 103.361901 \nL 212.616279 122.686156 \nL 212.730422 125.797236 \nL 212.654327 121.512834 \nL 212.749446 125.185687 \nL 212.76847 125.512795 \nL 212.787494 123.251484 \nL 212.844566 126.959892 \nL 212.901638 129.562533 \nL 212.939685 126.558118 \nL 212.958709 126.508341 \nL 213.091877 118.508419 \nL 213.110901 119.500409 \nL 213.167972 116.684437 \nL 213.225044 113.367136 \nL 213.282116 115.422227 \nL 213.339188 118.369754 \nL 213.415283 118.327087 \nL 213.434307 119.19819 \nL 213.472355 116.67377 \nL 213.624546 110.184945 \nL 213.73869 108.261408 \nL 213.757714 108.68096 \nL 213.890881 113.864909 \nL 214.005025 111.795596 \nL 213.986001 114.056907 \nL 214.043073 111.920039 \nL 214.08112 114.113795 \nL 214.119168 112.286258 \nL 214.157216 109.352953 \nL 214.195264 113.104028 \nL 214.27136 110.928049 \nL 214.347455 118.41242 \nL 214.480623 112.855141 \nL 214.556718 110.451609 \nL 214.594766 110.860494 \nL 214.61379 112.890696 \nL 214.689886 109.168066 \nL 214.70891 108.552961 \nL 214.727934 111.475599 \nL 214.746957 113.818687 \nL 214.804029 108.698738 \nL 214.823053 108.652516 \nL 214.918173 108.54585 \nL 215.05134 115.06312 \nL 215.108412 119.596408 \nL 215.222555 131.279849 \nL 215.298651 130.369636 \nL 215.317675 130.757188 \nL 215.355723 129.729642 \nL 215.412795 126.785671 \nL 215.58401 114.497792 \nL 215.622058 117.21421 \nL 215.774249 112.339591 \nL 215.660105 119.784851 \nL 215.793273 113.360025 \nL 215.869369 111.425822 \nL 215.888392 112.702254 \nL 215.907416 113.328025 \nL 215.92644 112.09426 \nL 215.945464 112.84803 \nL 215.983512 110.504942 \nL 216.059608 112.13337 \nL 216.097656 110.881827 \nL 216.116679 114.739567 \nL 216.192775 109.744061 \nL 216.211799 112.631143 \nL 216.230823 110.860494 \nL 216.268871 115.26934 \nL 216.306919 112.997362 \nL 216.573253 119.137746 \nL 216.344966 111.400933 \nL 216.592277 118.426642 \nL 216.630325 118.440864 \nL 216.839588 104.357447 \nL 216.915684 113.6338 \nL 216.972756 111.191158 \nL 216.99178 106.565425 \nL 217.010804 116.929768 \nL 217.048851 115.539559 \nL 217.105923 121.978607 \nL 217.086899 113.413358 \nL 217.162995 119.240856 \nL 217.182019 112.762698 \nL 217.258114 121.363502 \nL 217.277138 115.418672 \nL 217.296162 120.023071 \nL 217.372258 112.876474 \nL 217.448354 117.335097 \nL 217.486401 114.433792 \nL 217.562497 114.960009 \nL 217.600545 111.724486 \nL 217.638593 110.224056 \nL 217.714688 113.893353 \nL 217.733712 111.368934 \nL 217.790784 116.343107 \nL 217.942975 122.440825 \nL 217.981023 124.069253 \nL 218.019071 120.943951 \nL 218.190286 116.53155 \nL 218.228334 116.595549 \nL 218.361502 121.669277 \nL 218.399549 121.015061 \nL 218.684908 114.220461 \nL 218.74198 116.357329 \nL 218.761004 116.709326 \nL 218.780028 116.268441 \nL 218.799052 116.346662 \nL 218.875147 113.772466 \nL 218.913195 114.366237 \nL 218.932219 114.408904 \nL 219.046363 109.790282 \nL 219.122458 110.821383 \nL 219.198554 112.496034 \nL 219.236602 111.184046 \nL 219.255626 110.259611 \nL 219.312697 111.294268 \nL 219.331721 112.140482 \nL 219.407817 110.881827 \nL 219.483913 109.19651 \nL 219.52196 110.49072 \nL 219.693176 117.125322 \nL 219.750247 118.903082 \nL 219.826343 118.042646 \nL 219.864391 117.836426 \nL 219.883415 118.853305 \nL 219.940487 117.541317 \nL 219.997558 114.512014 \nL 220.05463 114.92801 \nL 220.130726 116.439106 \nL 220.168774 115.639114 \nL 220.206821 113.80091 \nL 220.244869 114.821344 \nL 220.282917 117.772426 \nL 220.339989 114.842677 \nL 220.359013 114.202684 \nL 220.397061 114.970676 \nL 220.549252 119.390188 \nL 220.5873 119.340411 \nL 220.606324 119.567964 \nL 220.663395 121.448835 \nL 220.720467 119.923516 \nL 220.853635 117.733316 \nL 220.910706 118.565307 \nL 220.948754 117.509318 \nL 220.967778 117.551984 \nL 220.986802 117.31732 \nL 221.005826 117.55554 \nL 221.081922 119.173301 \nL 221.100946 118.391087 \nL 221.215089 114.867566 \nL 221.234113 115.425783 \nL 221.253137 115.827556 \nL 221.310209 114.7609 \nL 221.36728 113.399136 \nL 221.405328 114.597346 \nL 221.443376 116.218664 \nL 221.500448 114.106684 \nL 221.652639 111.560932 \nL 221.671663 111.464933 \nL 221.690687 111.575154 \nL 221.766783 109.509396 \nL 221.80483 110.551164 \nL 221.842878 112.293369 \nL 221.918974 111.258712 \nL 221.937998 111.301379 \nL 221.957022 110.892494 \nL 221.976046 112.851586 \nL 221.99507 112.279147 \nL 222.033117 113.200027 \nL 222.090189 111.884484 \nL 222.109213 111.92715 \nL 222.280428 114.874677 \nL 222.299452 114.622235 \nL 222.318476 115.180452 \nL 222.356524 115.03112 \nL 222.43262 117.171543 \nL 222.470667 116.474661 \nL 222.508715 115.575114 \nL 222.565787 116.879991 \nL 222.584811 117.0791 \nL 222.603835 116.172442 \nL 222.660907 115.180452 \nL 222.698954 116.104887 \nL 222.717978 116.247108 \nL 222.737002 115.792001 \nL 222.756026 115.240896 \nL 222.794074 115.856001 \nL 222.984313 120.307513 \nL 223.269672 117.036433 \nL 223.383815 119.991071 \nL 223.421863 118.319976 \nL 223.440887 118.298643 \nL 223.459911 116.748436 \nL 223.555031 117.299542 \nL 223.574055 117.31732 \nL 223.707222 114.152906 \nL 223.726246 114.526236 \nL 223.783318 115.226673 \nL 223.802342 114.440903 \nL 223.859413 112.186703 \nL 223.916485 113.555579 \nL 223.935509 114.58668 \nL 224.011605 112.730698 \nL 224.125748 114.273794 \nL 224.049653 112.613366 \nL 224.144772 113.683577 \nL 224.163796 113.943131 \nL 224.201844 113.480913 \nL 224.220868 113.512913 \nL 224.27794 112.364479 \nL 224.335011 112.727142 \nL 224.411107 114.003574 \nL 224.468179 113.875576 \nL 224.487203 113.996463 \nL 224.563298 116.385773 \nL 224.601346 115.440005 \nL 224.62037 115.201785 \nL 224.639394 115.720891 \nL 224.658418 115.699558 \nL 224.677442 116.197331 \nL 224.71549 114.775122 \nL 224.734514 114.86401 \nL 224.772561 114.014241 \nL 224.829633 115.169785 \nL 224.867681 114.89601 \nL 224.886705 115.37245 \nL 224.962801 114.984898 \nL 225.05792 115.54667 \nL 225.114992 115.240896 \nL 225.15304 115.091564 \nL 225.210111 114.188461 \nL 225.248159 115.052453 \nL 225.286207 116.197331 \nL 225.343279 115.454227 \nL 225.362303 114.718234 \nL 225.419375 115.568003 \nL 225.476446 116.986656 \nL 225.533518 116.794658 \nL 225.552542 115.888 \nL 225.628638 116.851546 \nL 225.647662 116.766214 \nL 225.685709 117.487985 \nL 225.742781 116.84088 \nL 225.894972 116.140442 \nL 225.913996 116.60266 \nL 225.990092 115.048897 \nL 226.02814 115.930667 \nL 226.085212 117.72976 \nL 226.142283 116.350218 \nL 226.161307 115.948444 \nL 226.199355 116.567105 \nL 226.218379 116.549327 \nL 226.237403 116.766214 \nL 226.256427 116.058665 \nL 226.408618 114.206239 \nL 226.427642 114.352015 \nL 226.503738 116.577771 \nL 226.541786 115.568003 \nL 226.560809 114.956454 \nL 226.636905 116.069332 \nL 226.80812 113.683577 \nL 226.827144 113.740466 \nL 226.846168 113.701355 \nL 226.99836 114.871121 \nL 227.112503 113.719133 \nL 227.036407 115.080897 \nL 227.169575 113.808021 \nL 227.283718 115.368894 \nL 227.302742 114.547569 \nL 227.378838 115.983999 \nL 227.492981 114.38046 \nL 227.531029 114.757345 \nL 227.550053 114.7609 \nL 227.664197 115.589337 \nL 227.702244 115.379561 \nL 227.797364 116.02311 \nL 227.835412 115.770668 \nL 227.911508 114.408904 \nL 227.968579 115.180452 \nL 228.139795 116.734214 \nL 228.253938 117.221321 \nL 228.330034 115.614225 \nL 228.387105 116.094221 \nL 228.406129 116.271997 \nL 228.425153 115.582226 \nL 228.444177 115.571559 \nL 228.463201 115.400894 \nL 228.520273 115.792001 \nL 228.634416 116.307552 \nL 228.65344 116.005332 \nL 228.710512 115.447116 \nL 228.729536 116.037332 \nL 228.767584 115.927111 \nL 228.786608 116.065776 \nL 228.900751 114.68979 \nL 228.919775 114.7609 \nL 228.976847 114.334238 \nL 229.014895 114.465792 \nL 229.205134 116.133331 \nL 229.357325 115.105786 \nL 229.395373 115.006231 \nL 229.452445 113.779577 \nL 229.509517 114.369793 \nL 229.62366 115.514671 \nL 229.642684 115.276451 \nL 229.680732 116.19022 \nL 229.699756 115.617781 \nL 229.71878 115.792001 \nL 229.870971 113.882687 \nL 230.099258 115.905778 \nL 230.232425 115.020453 \nL 230.251449 114.664901 \nL 230.308521 115.002676 \nL 230.422664 115.909333 \nL 230.346569 114.960009 \nL 230.460712 115.827556 \nL 230.479736 115.941333 \nL 230.49876 115.468449 \nL 230.555832 115.781335 \nL 230.59388 115.866667 \nL 230.669975 115.105786 \nL 230.803143 116.321774 \nL 230.822167 115.891556 \nL 230.841191 116.577771 \nL 230.917286 116.008888 \nL 230.93631 116.243552 \nL 230.974358 115.671114 \nL 231.145573 114.8249 \nL 231.164597 114.871121 \nL 231.183621 114.888899 \nL 231.202645 114.732456 \nL 231.221669 115.027564 \nL 231.240693 114.977787 \nL 231.392884 115.536004 \nL 231.46898 115.03112 \nL 231.526052 115.155563 \nL 231.583123 115.13423 \nL 231.697267 115.61067 \nL 231.716291 115.304895 \nL 231.773363 115.664003 \nL 231.792386 115.912889 \nL 231.868482 115.482671 \nL 231.925554 116.008888 \nL 231.963602 115.774224 \nL 232.134817 114.604457 \nL 232.191889 115.287117 \nL 232.24896 114.974232 \nL 232.267984 114.988454 \nL 232.420176 115.678225 \nL 232.4392 115.728002 \nL 232.477247 115.550226 \nL 232.610415 114.817789 \nL 232.629439 114.785789 \nL 232.667487 114.860455 \nL 232.78163 115.600003 \nL 232.800654 115.450671 \nL 232.838702 115.582226 \nL 232.87675 115.436449 \nL 232.914798 115.276451 \nL 232.952845 115.461338 \nL 232.971869 115.408005 \nL 232.990893 115.457782 \nL 233.009917 115.358228 \nL 233.086013 115.109341 \nL 233.105037 115.294228 \nL 233.162108 115.528893 \nL 233.143085 115.26934 \nL 233.21918 115.333339 \nL 233.333324 114.981343 \nL 233.352348 115.10223 \nL 233.523563 115.557337 \nL 233.580635 115.376005 \nL 233.675754 114.984898 \nL 233.713802 115.098675 \nL 233.770874 114.974232 \nL 233.808922 115.116452 \nL 233.942089 116.090665 \nL 233.999161 115.905778 \nL 234.1894 114.899566 \nL 234.360615 115.557337 \nL 234.379639 115.361783 \nL 234.455735 115.724446 \nL 234.607926 115.198229 \nL 234.493783 115.742224 \nL 234.664998 115.376005 \nL 234.72207 115.525337 \nL 234.703046 115.265784 \nL 234.779141 115.493338 \nL 234.912309 115.20534 \nL 234.950357 115.283562 \nL 234.96938 115.16623 \nL 234.988404 115.233785 \nL 235.045476 114.856899 \nL 235.140596 114.949343 \nL 235.15962 115.297784 \nL 235.235715 114.903121 \nL 235.254739 115.144896 \nL 235.273763 114.938676 \nL 235.330835 115.34045 \nL 235.349859 115.244451 \nL 235.387907 115.230229 \nL 235.406931 115.091564 \nL 235.425954 115.368894 \nL 235.464002 115.294228 \nL 235.578146 115.735113 \nL 235.50205 115.20534 \nL 235.635218 115.585781 \nL 235.654241 115.283562 \nL 235.749361 115.290673 \nL 235.844481 115.365339 \nL 235.863505 115.26934 \nL 235.920576 115.095119 \nL 235.9396 115.390227 \nL 235.996672 115.543115 \nL 236.053744 115.216007 \nL 236.110815 115.319117 \nL 236.129839 115.479115 \nL 236.167887 115.272895 \nL 236.205935 115.294228 \nL 236.301055 115.255118 \nL 236.243983 115.358228 \nL 236.320079 115.30845 \nL 236.37715 115.518226 \nL 236.434222 115.440005 \nL 236.510318 115.550226 \nL 236.529342 115.358228 \nL 236.567389 115.671114 \nL 236.586413 115.564448 \nL 236.605437 115.745779 \nL 236.662509 115.454227 \nL 236.738605 115.248007 \nL 236.795676 115.365339 \nL 236.8147 115.415116 \nL 236.833724 115.212451 \nL 236.871772 115.255118 \nL 237.00494 115.052453 \nL 237.195179 115.379561 \nL 237.385418 115.123563 \nL 237.44249 115.50756 \nL 237.499561 115.358228 \nL 237.537609 115.294228 \nL 237.556633 115.40445 \nL 237.575657 115.390227 \nL 237.613705 115.600003 \nL 237.670777 115.514671 \nL 237.803944 115.098675 \nL 237.822968 115.322673 \nL 237.899064 114.99912 \nL 238.108327 115.632003 \nL 238.184422 115.440005 \nL 238.241494 115.304895 \nL 238.298566 115.333339 \nL 238.355638 115.482671 \nL 238.393685 115.201785 \nL 238.526853 115.557337 \nL 238.431733 115.13423 \nL 238.545877 115.500449 \nL 238.602948 115.37245 \nL 238.583925 115.582226 \nL 238.621972 115.575114 \nL 238.640996 115.596448 \nL 238.774164 115.262229 \nL 238.869283 115.066675 \nL 238.945379 115.336895 \nL 238.983427 115.319117 \nL 239.002451 115.294228 \nL 239.021475 115.361783 \nL 239.116594 115.493338 \nL 239.154642 115.429338 \nL 239.287809 115.052453 \nL 239.306833 115.098675 \nL 239.401953 115.358228 \nL 239.420977 115.262229 \nL 239.440001 115.187563 \nL 239.459025 115.415116 \nL 239.497073 115.347561 \nL 239.63024 115.50756 \nL 239.649264 115.233785 \nL 239.744383 115.272895 \nL 239.858527 115.585781 \nL 239.896575 115.521782 \nL 239.915599 115.386672 \nL 239.991694 115.592892 \nL 240.105838 115.219562 \nL 240.16291 115.276451 \nL 240.200957 115.365339 \nL 240.258029 115.26934 \nL 240.315101 115.077342 \nL 240.372173 115.248007 \nL 240.391197 115.212451 \nL 240.410221 115.226673 \nL 240.467292 115.454227 \nL 240.524364 115.304895 \nL 240.543388 115.148452 \nL 240.562412 115.461338 \nL 240.638508 115.258673 \nL 240.657531 115.400894 \nL 240.676555 115.194674 \nL 240.714603 115.212451 \nL 240.733627 115.123563 \nL 240.809723 115.23734 \nL 240.866795 115.351117 \nL 240.904842 115.560892 \nL 240.999962 115.454227 \nL 241.114105 115.162674 \nL 241.152153 115.10223 \nL 241.228249 115.336895 \nL 241.247273 115.276451 \nL 241.266297 115.425783 \nL 241.304345 115.400894 \nL 241.361416 115.600003 \nL 241.437512 115.575114 \nL 241.589703 115.141341 \nL 241.627751 115.03112 \nL 241.665799 115.230229 \nL 241.684823 115.116452 \nL 241.760919 115.585781 \nL 241.81799 115.472004 \nL 241.91311 115.326228 \nL 241.932134 115.521782 \nL 242.00823 115.290673 \nL 242.027253 115.095119 \nL 242.103349 115.379561 \nL 242.122373 115.319117 \nL 242.141397 115.489782 \nL 242.198469 115.365339 \nL 242.293588 115.301339 \nL 242.312612 115.482671 \nL 242.35066 115.070231 \nL 242.426756 115.322673 \nL 242.521875 115.077342 \nL 242.578947 114.963565 \nL 242.636019 115.923556 \nL 242.731138 115.152008 \nL 242.750162 115.173341 \nL 242.864306 115.450671 \nL 242.902354 114.785789 \nL 242.978449 115.066675 \nL 242.997473 115.059564 \nL 243.092593 115.752891 \nL 243.111617 115.582226 \nL 243.206736 115.326228 \nL 243.22576 115.393783 \nL 243.244784 115.603559 \nL 243.301856 115.37245 \nL 243.358928 115.116452 \nL 243.415999 115.255118 \nL 243.473071 115.383116 \nL 243.511119 115.226673 \nL 243.530143 115.176896 \nL 243.587215 115.301339 \nL 243.644286 115.752891 \nL 243.701358 115.44356 \nL 243.75843 115.016898 \nL 243.815502 115.368894 \nL 243.872573 115.16623 \nL 243.910621 114.984898 \nL 243.967693 115.159119 \nL 244.024765 115.543115 \nL 244.062812 115.230229 \nL 244.119884 114.704012 \nL 244.176956 115.006231 \nL 244.234028 115.525337 \nL 244.291099 115.198229 \nL 244.310123 115.024009 \nL 244.367195 115.511115 \nL 244.424267 115.980444 \nL 244.462315 115.706669 \nL 244.519386 115.287117 \nL 244.576458 115.560892 \nL 244.595482 115.884445 \nL 244.671578 115.358228 \nL 244.690602 115.287117 \nL 244.72865 115.500449 \nL 244.785721 115.916444 \nL 244.842793 115.568003 \nL 244.899865 115.052453 \nL 244.956937 115.390227 \nL 244.97596 115.450671 \nL 245.014008 115.226673 \nL 245.109128 114.327127 \nL 245.1662 114.636457 \nL 245.204247 116.503105 \nL 245.261319 113.896909 \nL 245.299367 116.154664 \nL 245.356439 117.59465 \nL 245.413511 114.849788 \nL 245.470582 113.288915 \nL 245.527654 119.443521 \nL 245.565702 111.568043 \nL 245.641798 116.311107 \nL 245.660821 117.701316 \nL 245.698869 113.470246 \nL 245.736917 117.007989 \nL 245.774965 112.837364 \nL 245.793989 116.108443 \nL 245.813013 120.979506 \nL 245.870085 111.450711 \nL 245.908132 117.978646 \nL 245.927156 111.440044 \nL 246.022276 116.595549 \nL 246.0413 116.325329 \nL 246.079348 118.913748 \nL 246.155443 105.587657 \nL 246.212515 160.844004 \nL 246.231539 145.651264 \nL 246.269587 50.107312 \nL 246.307635 157.704479 \nL 246.345682 83.337209 \nL 246.402754 163.286646 \nL 246.421778 133.850491 \nL 246.440802 53.357058 \nL 246.497874 157.871588 \nL 246.535922 94.896206 \nL 246.592993 125.996346 \nL 246.631041 91.532684 \nL 246.650065 113.143138 \nL 246.688113 106.867644 \nL 246.783232 169.395031 \nL 246.802256 109.889837 \nL 246.82128 22.224919 \nL 246.859328 178.30161 \nL 246.897376 60.606765 \nL 246.954448 165.334626 \nL 246.992496 64.236952 \nL 247.011519 17.083636 \nL 247.049567 194.696116 \nL 247.201759 51.255746 \nL 247.220783 96.094417 \nL 247.239806 169.579918 \nL 247.315902 159.432462 \nL 247.391998 34.935906 \nL 247.411022 121.918163 \nL 247.430046 159.276019 \nL 247.44907 103.763675 \nL 247.506141 134.778482 \nL 247.525165 63.828067 \nL 247.563213 165.899954 \nL 247.601261 105.619657 \nL 247.620285 157.914255 \nL 247.658333 94.209991 \nL 247.69638 145.573042 \nL 247.715404 82.714992 \nL 247.810524 129.775864 \nL 247.848572 102.053469 \nL 247.867596 173.970986 \nL 247.905644 29.382182 \nL 247.943691 162.120436 \nL 247.962715 92.218899 \nL 248.000763 175.421638 \nL 248.057835 133.000721 \nL 248.095883 80.741678 \nL 248.114907 92.115789 \nL 248.191002 210.742181 \nL 248.171978 74.427074 \nL 248.22905 105.975209 \nL 248.286122 129.651421 \nL 248.267098 56.898357 \nL 248.343194 124.52436 \nL 248.381241 160.310676 \nL 248.457337 49.595317 \nL 248.552457 173.832321 \nL 248.571481 102.565464 \nL 248.647576 89.278484 \nL 248.6666 104.908552 \nL 248.742696 161.587108 \nL 248.704648 98.128175 \nL 248.76172 104.744999 \nL 248.799768 121.228392 \nL 248.818792 78.099927 \nL 248.837815 147.009473 \nL 248.875863 137.498455 \nL 248.894887 170.219912 \nL 248.913911 91.376241 \nL 248.970983 118.871082 \nL 248.990007 105.95032 \nL 249.009031 134.824703 \nL 249.066102 128.193657 \nL 249.085126 140.659313 \nL 249.10415 105.783211 \nL 249.142198 136.812239 \nL 249.180246 85.580742 \nL 249.256342 119.294189 \nL 249.313413 90.579804 \nL 249.294389 130.277192 \nL 249.370485 110.440943 \nL 249.408533 92.730894 \nL 249.465605 134.917147 \nL 249.484629 95.177092 \nL 249.579748 123.016819 \nL 249.617796 126.703894 \nL 249.655844 102.739685 \nL 249.693892 130.494079 \nL 249.73194 107.674748 \nL 249.789011 130.710966 \nL 249.808035 98.249062 \nL 249.827059 88.858932 \nL 249.846083 135.848693 \nL 249.884131 84.81275 \nL 249.941203 116.083554 \nL 249.960227 126.060345 \nL 249.998274 102.181468 \nL 250.036322 117.203543 \nL 250.055346 116.684437 \nL 250.112418 128.574098 \nL 250.188513 96.855298 \nL 250.283633 130.298526 \nL 250.302657 111.390267 \nL 250.321681 110.910271 \nL 250.340705 136.694907 \nL 250.378753 100.837481 \nL 250.435824 128.680764 \nL 250.454848 103.568121 \nL 250.549968 115.806223 \nL 250.645087 103.497011 \nL 250.60704 126.369675 \nL 250.664111 111.230268 \nL 250.683135 134.309153 \nL 250.721183 96.773521 \nL 250.759231 117.075544 \nL 250.778255 107.731636 \nL 250.816303 124.997244 \nL 250.873374 111.735152 \nL 251.025566 125.943013 \nL 251.139709 107.301418 \nL 251.158733 126.149233 \nL 251.253853 111.315601 \nL 251.291901 117.687094 \nL 251.329948 105.381437 \nL 251.367996 124.894134 \nL 251.444092 107.767191 \nL 251.463116 106.248984 \nL 251.539212 124.087031 \nL 251.577259 120.830174 \nL 251.596283 107.258752 \nL 251.691403 115.098675 \nL 251.729451 121.00795 \nL 251.748475 117.281764 \nL 251.786522 107.148531 \nL 251.805546 121.605278 \nL 251.843594 111.315601 \nL 251.881642 121.235503 \nL 251.957738 117.551984 \nL 252.014809 107.472083 \nL 251.995786 118.679084 \nL 252.033833 113.370692 \nL 252.109929 123.614147 \nL 252.128953 109.1574 \nL 252.281144 119.703074 \nL 252.376264 110.629385 \nL 252.395288 110.661385 \nL 252.471383 110.021391 \nL 252.490407 123.902144 \nL 252.509431 105.836543 \nL 252.585527 127.031002 \nL 252.604551 106.174318 \nL 252.623575 123.73859 \nL 252.69967 106.08543 \nL 252.718694 117.246209 \nL 252.756742 110.440943 \nL 252.775766 123.905699 \nL 252.79479 112.826697 \nL 252.813814 122.120828 \nL 252.851862 110.732495 \nL 252.88991 114.092462 \nL 252.927957 111.905817 \nL 252.946981 116.115554 \nL 252.966005 120.954617 \nL 253.042101 114.273794 \nL 253.080149 108.776959 \nL 253.118197 119.176857 \nL 253.137221 118.760861 \nL 253.156244 110.348499 \nL 253.251364 113.068472 \nL 253.346484 118.536863 \nL 253.289412 110.32361 \nL 253.384531 117.452429 \nL 253.403555 119.159079 \nL 253.422579 104.414335 \nL 253.441603 122.565268 \nL 253.517699 113.153805 \nL 253.593795 122.913709 \nL 253.612818 116.506661 \nL 253.631842 112.560033 \nL 253.707938 116.53155 \nL 253.726962 122.821266 \nL 253.803058 113.637356 \nL 253.841105 116.232886 \nL 253.860129 116.008888 \nL 253.879153 105.495213 \nL 253.936225 119.141302 \nL 253.974273 106.572536 \nL 254.088416 117.804426 \nL 254.10744 116.503105 \nL 254.126464 116.239997 \nL 254.145488 116.339551 \nL 254.164512 113.217804 \nL 254.240608 117.822204 \nL 254.259632 114.017796 \nL 254.316703 117.701316 \nL 254.335727 116.12622 \nL 254.354751 111.696041 \nL 254.430847 117.043545 \nL 254.449871 116.488883 \nL 254.468895 120.815952 \nL 254.54499 114.042685 \nL 254.621086 117.057767 \nL 254.64011 112.37159 \nL 254.659134 116.161775 \nL 254.678158 116.047999 \nL 254.697182 117.167988 \nL 254.716206 114.572458 \nL 254.735229 107.678303 \nL 254.830349 111.660486 \nL 254.849373 117.96798 \nL 254.944493 115.902222 \nL 255.020588 113.619578 \nL 255.001564 118.917304 \nL 255.039612 115.998221 \nL 255.058636 115.621336 \nL 255.07766 122.803488 \nL 255.115708 111.95915 \nL 255.17278 120.613287 \nL 255.286923 110.088946 \nL 255.267899 121.509278 \nL 255.343995 112.784031 \nL 255.382043 119.703074 \nL 255.401067 115.454227 \nL 255.42009 107.294307 \nL 255.439114 120.175958 \nL 255.51521 112.602699 \nL 255.572282 120.239958 \nL 255.553258 110.558275 \nL 255.629354 116.453328 \nL 255.667401 109.630284 \nL 255.705449 120.467511 \nL 255.724473 111.290712 \nL 255.800569 119.297745 \nL 255.838617 114.174239 \nL 255.857641 110.110279 \nL 255.876664 119.130635 \nL 255.914712 111.600042 \nL 255.95276 123.155485 \nL 255.990808 110.476498 \nL 256.028856 116.997323 \nL 256.04788 111.493377 \nL 256.085928 118.1422 \nL 256.123975 117.370652 \nL 256.142999 119.553742 \nL 256.162023 108.012522 \nL 256.257143 112.417812 \nL 256.276167 122.543935 \nL 256.371286 116.801769 \nL 256.447382 122.846154 \nL 256.48543 110.124501 \nL 256.523478 123.372371 \nL 256.561525 107.425861 \nL 256.599573 116.446217 \nL 256.618597 117.427541 \nL 256.637621 113.224915 \nL 256.675669 116.780436 \nL 256.789812 107.600082 \nL 256.751765 119.50752 \nL 256.808836 112.215147 \nL 256.846884 122.778599 \nL 256.884932 111.24449 \nL 256.92298 115.155563 \nL 256.961028 108.773403 \nL 256.980052 116.620438 \nL 256.999076 118.977748 \nL 257.018099 113.064917 \nL 257.075171 116.449773 \nL 257.113219 117.345764 \nL 257.189315 110.451609 \nL 257.246386 118.85686 \nL 257.303458 115.902222 \nL 257.341506 119.219523 \nL 257.36053 111.262268 \nL 257.398578 119.852406 \nL 257.436626 109.086289 \nL 257.474673 119.678185 \nL 257.531745 107.560971 \nL 257.588817 115.756446 \nL 257.626865 112.001816 \nL 257.70296 118.085312 \nL 257.79808 120.659509 \nL 257.817104 110.451609 \nL 257.855152 119.98396 \nL 257.912224 110.039169 \nL 257.950271 119.151968 \nL 258.007343 112.400035 \nL 258.083439 113.082695 \nL 258.178558 119.919961 \nL 258.197582 118.10309 \nL 258.273678 118.949304 \nL 258.311726 112.833808 \nL 258.425869 120.63462 \nL 258.444893 120.549288 \nL 258.463917 106.615202 \nL 258.559037 109.964503 \nL 258.67318 116.791103 \nL 258.7683 113.004473 \nL 258.730252 119.187523 \nL 258.806348 113.900464 \nL 258.825371 119.329744 \nL 258.863419 110.312944 \nL 258.920491 116.929768 \nL 258.996587 117.463096 \nL 259.034635 110.334277 \nL 259.053658 121.51639 \nL 259.148778 118.078201 \nL 259.167802 109.456063 \nL 259.243898 118.405309 \nL 259.262922 115.368894 \nL 259.319993 111.845373 \nL 259.339017 115.742224 \nL 259.358041 118.415976 \nL 259.377065 111.941372 \nL 259.396089 114.533347 \nL 259.415113 110.430276 \nL 259.453161 116.972434 \nL 259.472185 114.99912 \nL 259.567304 119.411521 \nL 259.510232 109.985836 \nL 259.586328 116.122665 \nL 259.605352 109.392064 \nL 259.6434 117.911092 \nL 259.700472 113.399136 \nL 259.776567 112.385812 \nL 259.814615 121.07906 \nL 259.928759 110.952938 \nL 259.966806 117.271098 \nL 260.042902 113.143138 \nL 260.061926 118.216866 \nL 260.138022 115.880889 \nL 260.214117 110.07828 \nL 260.195093 118.899526 \nL 260.233141 114.519125 \nL 260.328261 120.737731 \nL 260.271189 112.808919 \nL 260.347285 115.009787 \nL 260.366309 112.424923 \nL 260.404357 116.623993 \nL 260.442404 114.03913 \nL 260.5185 113.004473 \nL 260.556548 119.319078 \nL 260.594596 112.161815 \nL 260.632644 121.384835 \nL 260.670691 112.563588 \nL 260.746787 112.193814 \nL 260.803859 119.624853 \nL 260.841907 111.770707 \nL 260.918002 114.814233 \nL 260.937026 117.310209 \nL 260.975074 109.953836 \nL 261.013122 116.670215 \nL 261.070194 112.965362 \nL 261.05117 117.171543 \nL 261.127265 114.209795 \nL 261.184337 117.65865 \nL 261.222385 113.466691 \nL 261.298481 110.504942 \nL 261.279457 118.063979 \nL 261.317505 113.918242 \nL 261.412624 112.88003 \nL 261.469696 118.977748 \nL 261.507744 110.533386 \nL 261.583839 115.966222 \nL 261.640911 111.944928 \nL 261.621887 118.494197 \nL 261.678959 113.715577 \nL 261.697983 120.417734 \nL 261.736031 112.624032 \nL 261.793102 118.017757 \nL 261.869198 112.471145 \nL 261.888222 119.255078 \nL 261.92627 113.146694 \nL 261.945294 118.319976 \nL 262.002365 112.787586 \nL 262.040413 114.771567 \nL 262.059437 111.095158 \nL 262.097485 119.514631 \nL 262.135533 111.802707 \nL 262.192605 117.374208 \nL 262.2687 116.385773 \nL 262.287724 118.10309 \nL 262.325772 113.466691 \nL 262.36382 115.47556 \nL 262.382844 110.675607 \nL 262.439916 118.255977 \nL 262.477963 113.818687 \nL 262.496987 112.872919 \nL 262.516011 115.376005 \nL 262.535035 120.581288 \nL 262.611131 113.672911 \nL 262.668203 118.65064 \nL 262.687226 113.811576 \nL 262.70625 110.579608 \nL 262.763322 118.831971 \nL 262.782346 112.481812 \nL 262.858442 118.127978 \nL 262.89649 113.73691 \nL 262.915513 113.6658 \nL 262.972585 112.766253 \nL 263.029657 117.76176 \nL 263.1438 113.512913 \nL 263.181848 119.40441 \nL 263.219896 110.682718 \nL 263.257944 115.841779 \nL 263.295992 117.911092 \nL 263.372087 112.556477 \nL 263.467207 110.80005 \nL 263.505255 120.421289 \nL 263.619398 112.5067 \nL 263.67647 118.952859 \nL 263.733542 117.655094 \nL 263.809638 111.624931 \nL 263.847685 116.623993 \nL 263.866709 116.591993 \nL 263.980853 111.016937 \nL 264.018901 119.208857 \nL 264.094996 118.110201 \nL 264.133044 109.669395 \nL 264.190116 117.711982 \nL 264.20914 117.783093 \nL 264.228164 111.85604 \nL 264.247188 118.92797 \nL 264.323283 115.059564 \nL 264.399379 117.807981 \nL 264.361331 114.305794 \nL 264.456451 116.353774 \nL 264.532546 112.055149 \nL 264.55157 116.236441 \nL 264.570594 118.437309 \nL 264.627666 113.722688 \nL 264.64669 115.422227 \nL 264.684738 115.813334 \nL 264.703762 115.347561 \nL 264.722786 113.559134 \nL 264.741809 116.922657 \nL 264.817905 114.366237 \nL 264.894001 114.010685 \nL 264.932049 117.665761 \nL 265.027168 118.316421 \nL 265.046192 111.166269 \nL 265.160336 119.059525 \nL 265.17936 112.908474 \nL 265.274479 115.386672 \nL 265.331551 117.331542 \nL 265.388623 112.904918 \nL 265.42667 118.711084 \nL 265.445694 111.14138 \nL 265.502766 115.13423 \nL 265.559838 113.790243 \nL 265.597886 116.588438 \nL 265.61691 111.088047 \nL 265.654957 118.632862 \nL 265.712029 113.018695 \nL 265.731053 118.216866 \nL 265.769101 112.144037 \nL 265.807149 118.124423 \nL 265.826173 113.470246 \nL 265.921292 114.387571 \nL 265.940316 114.750234 \nL 265.95934 114.433792 \nL 265.978364 118.497752 \nL 266.016412 112.325369 \nL 266.073484 117.043545 \nL 266.092507 113.313803 \nL 266.187627 114.718234 \nL 266.244699 117.747538 \nL 266.225675 113.491579 \nL 266.301771 117.544873 \nL 266.320794 113.004473 \nL 266.415914 113.35647 \nL 266.472986 118.280866 \nL 266.49201 111.724486 \nL 266.549081 115.724446 \nL 266.568105 116.26133 \nL 266.644201 113.11825 \nL 266.606153 118.739528 \nL 266.682249 115.78489 \nL 266.701273 117.11821 \nL 266.720297 113.207138 \nL 266.758345 114.821344 \nL 266.777368 113.168027 \nL 266.796392 117.982202 \nL 266.83444 114.579569 \nL 266.92956 118.949304 \nL 266.891512 113.331581 \nL 266.948584 116.147553 \nL 266.986632 110.775162 \nL 267.024679 118.778639 \nL 267.062727 114.693345 \nL 267.081751 114.647124 \nL 267.176871 117.310209 \nL 267.157847 113.239137 \nL 267.195895 116.090665 \nL 267.252966 117.327986 \nL 267.291014 111.717375 \nL 267.405158 118.846194 \nL 267.500277 119.656852 \nL 267.538325 111.358267 \nL 267.576373 117.452429 \nL 267.652469 115.600003 \nL 267.70954 116.961768 \nL 267.728564 113.815132 \nL 267.747588 117.69776 \nL 267.842708 115.944889 \nL 267.861732 111.642709 \nL 267.880756 117.992869 \nL 267.937827 115.628447 \nL 267.975875 117.608872 \nL 268.090019 113.377803 \nL 268.109043 116.079998 \nL 268.204162 115.436449 \nL 268.261234 113.939575 \nL 268.280258 116.961768 \nL 268.299282 114.739567 \nL 268.33733 117.502207 \nL 268.356354 114.266683 \nL 268.375377 113.452469 \nL 268.413425 116.538661 \nL 268.432449 114.8249 \nL 268.451473 118.647084 \nL 268.527569 111.760041 \nL 268.546593 116.257774 \nL 268.603664 116.91199 \nL 268.660736 113.729799 \nL 268.77488 118.014202 \nL 268.927071 113.559134 \nL 268.965119 117.15021 \nL 269.022191 116.990212 \nL 269.041215 113.434691 \nL 269.136334 114.469348 \nL 269.155358 117.59465 \nL 269.21243 114.412459 \nL 269.250478 115.614225 \nL 269.269502 115.660447 \nL 269.326573 119.57152 \nL 269.383645 111.987594 \nL 269.421693 119.336855 \nL 269.497789 116.837324 \nL 269.55486 117.107544 \nL 269.630956 113.35647 \nL 269.726076 117.007989 \nL 269.745099 116.097776 \nL 269.764123 112.43559 \nL 269.783147 116.346662 \nL 269.859243 115.080897 \nL 269.878267 116.250663 \nL 269.897291 113.854242 \nL 269.935339 114.661346 \nL 270.011434 112.915585 \nL 269.973386 118.739528 \nL 270.030458 113.879131 \nL 270.049482 118.575974 \nL 270.08753 110.849828 \nL 270.144602 117.239098 \nL 270.182649 111.383156 \nL 270.201673 117.573317 \nL 270.258745 114.707567 \nL 270.296793 117.068433 \nL 270.334841 114.561791 \nL 270.372889 116.787547 \nL 270.487032 113.715577 \nL 270.544104 112.563588 \nL 270.601176 119.639075 \nL 270.639223 111.468488 \nL 270.715319 111.784929 \nL 270.753367 117.978646 \nL 270.829463 113.448913 \nL 270.905558 116.119109 \nL 270.96263 115.326228 \nL 270.981654 115.50756 \nL 271.05775 117.267542 \nL 271.095797 111.376045 \nL 271.114821 117.807981 \nL 271.209941 115.464893 \nL 271.247989 117.15021 \nL 271.267013 114.992009 \nL 271.362132 113.331581 \nL 271.305061 116.993767 \nL 271.381156 114.38046 \nL 271.40018 117.847092 \nL 271.438228 113.651578 \nL 271.476276 117.374208 \nL 271.514324 113.146694 \nL 271.609443 114.103129 \nL 271.628467 116.659548 \nL 271.704563 115.130674 \nL 271.723587 114.149351 \nL 271.761635 115.095119 \nL 271.780658 117.039989 \nL 271.818706 114.664901 \nL 271.856754 115.696002 \nL 271.894802 112.812475 \nL 271.93285 116.090665 \nL 271.970898 116.983101 \nL 272.085041 112.656032 \nL 272.199185 117.683538 \nL 272.218209 112.972473 \nL 272.313328 115.852445 \nL 272.389424 118.252422 \nL 272.351376 112.894252 \nL 272.408448 117.448874 \nL 272.446496 110.80005 \nL 272.484543 118.177756 \nL 272.522591 114.640013 \nL 272.598687 113.808021 \nL 272.617711 117.928869 \nL 272.693806 113.303137 \nL 272.731854 115.703113 \nL 272.788926 113.392025 \nL 272.80795 116.97599 \nL 272.90307 116.510216 \nL 272.998189 113.804465 \nL 272.941117 116.655993 \nL 273.017213 113.964464 \nL 273.131357 116.915546 \nL 273.169404 113.111139 \nL 273.207452 117.349319 \nL 273.2455 113.121805 \nL 273.283548 116.719992 \nL 273.302572 112.496034 \nL 273.359644 115.84889 \nL 273.378667 115.738668 \nL 273.454763 117.086211 \nL 273.492811 113.274693 \nL 273.568907 117.132433 \nL 273.606954 115.418672 \nL 273.625978 113.249804 \nL 273.664026 118.131534 \nL 273.702074 113.42758 \nL 273.721098 116.232886 \nL 273.816217 115.393783 \nL 273.835241 113.253359 \nL 273.854265 115.870223 \nL 273.930361 114.277349 \nL 273.949385 116.858657 \nL 274.044504 115.564448 \nL 274.063528 113.683577 \nL 274.1206 117.054211 \nL 274.158648 113.744021 \nL 274.272791 116.492439 \nL 274.291815 115.788446 \nL 274.310839 116.019555 \nL 274.329863 115.632003 \nL 274.348887 113.857798 \nL 274.386935 115.863112 \nL 274.424983 115.070231 \nL 274.482055 113.644467 \nL 274.520102 117.303098 \nL 274.539126 114.736012 \nL 274.634246 114.768011 \nL 274.710342 116.058665 \nL 274.729365 114.064018 \nL 274.748389 114.192017 \nL 274.843509 117.207098 \nL 274.862533 114.668457 \nL 274.881557 113.825798 \nL 274.900581 115.109341 \nL 274.919605 115.077342 \nL 274.9957 114.490681 \nL 275.033748 117.338653 \nL 275.052772 112.688032 \nL 275.147892 114.096018 \nL 275.166916 118.305754 \nL 275.262035 116.094221 \nL 275.281059 113.968019 \nL 275.357155 116.175997 \nL 275.376179 114.906677 \nL 275.43325 113.655133 \nL 275.471298 118.693306 \nL 275.509346 113.18936 \nL 275.585442 114.629346 \nL 275.604466 118.366198 \nL 275.642513 113.267582 \nL 275.680561 116.339551 \nL 275.699585 114.259572 \nL 275.794705 115.863112 \nL 275.889824 114.899566 \nL 275.908848 115.162674 \nL 275.984944 114.52268 \nL 276.022992 117.644428 \nL 276.137135 113.73691 \nL 276.175183 116.691548 \nL 276.251279 115.624892 \nL 276.289327 113.978686 \nL 276.308351 118.220422 \nL 276.365422 113.921797 \nL 276.40347 116.63466 \nL 276.460542 113.918242 \nL 276.517614 115.187563 \nL 276.593709 113.509357 \nL 276.612733 116.727103 \nL 276.631757 114.643568 \nL 276.669805 117.434652 \nL 276.726877 114.68979 \nL 276.783948 114.177795 \nL 276.860044 116.929768 \nL 276.93614 114.707567 \nL 276.974188 114.974232 \nL 276.993212 116.723548 \nL 277.031259 114.220461 \nL 277.088331 115.447116 \nL 277.107355 115.795557 \nL 277.126379 115.393783 \nL 277.145403 114.035574 \nL 277.202475 116.097776 \nL 277.221499 115.728002 \nL 277.240522 115.493338 \nL 277.259546 116.677326 \nL 277.27857 113.363581 \nL 277.354666 116.595549 \nL 277.430762 114.426681 \nL 277.468809 115.521782 \nL 277.487833 115.614225 \nL 277.506857 114.68979 \nL 277.582953 115.969777 \nL 277.601977 114.988454 \nL 277.621001 115.230229 \nL 277.640025 114.960009 \nL 277.659049 115.088008 \nL 277.678073 114.259572 \nL 277.71612 115.845334 \nL 277.754168 115.436449 \nL 277.830264 115.44356 \nL 277.868312 114.34846 \nL 277.906359 116.727103 \nL 277.982455 115.54667 \nL 278.001479 114.064018 \nL 278.039527 116.638215 \nL 278.096599 115.262229 \nL 278.15367 115.742224 \nL 278.210742 114.138684 \nL 278.24879 116.044443 \nL 278.324886 115.358228 \nL 278.420005 114.092462 \nL 278.362933 116.083554 \nL 278.439029 115.16623 \nL 278.534149 117.125322 \nL 278.515125 113.146694 \nL 278.553173 115.585781 \nL 278.572197 114.650679 \nL 278.629268 117.210654 \nL 278.667316 114.92801 \nL 278.743412 114.465792 \nL 278.800484 116.065776 \nL 278.838531 114.387571 \nL 278.914627 115.653336 \nL 278.952675 114.145795 \nL 278.971699 115.895111 \nL 278.990723 116.275552 \nL 279.028771 115.127119 \nL 279.047794 115.518226 \nL 279.085842 114.366237 \nL 279.104866 116.133331 \nL 279.161938 114.55468 \nL 279.199986 115.795557 \nL 279.276081 115.68178 \nL 279.314129 115.564448 \nL 279.333153 114.032019 \nL 279.352177 115.905778 \nL 279.409249 114.711123 \nL 279.466321 114.58668 \nL 279.523392 115.891556 \nL 279.56144 115.152008 \nL 279.65656 115.34045 \nL 279.675584 115.479115 \nL 279.751679 114.480014 \nL 279.713632 116.385773 \nL 279.789727 114.736012 \nL 279.884847 114.725345 \nL 279.903871 115.912889 \nL 279.922895 114.778678 \nL 280.018014 115.276451 \nL 280.056062 115.006231 \nL 280.132158 114.906677 \nL 280.170206 115.696002 \nL 280.246301 114.515569 \nL 280.208253 116.179553 \nL 280.265325 114.583124 \nL 280.360445 116.463995 \nL 280.322397 113.761799 \nL 280.379469 115.99111 \nL 280.417516 114.558236 \nL 280.493612 115.262229 \nL 280.512636 115.78489 \nL 280.569708 114.551125 \nL 280.607756 115.457782 \nL 280.645803 115.216007 \nL 280.683851 115.934222 \nL 280.778971 116.378662 \nL 280.817019 114.248905 \nL 280.855067 116.915546 \nL 280.893114 113.832909 \nL 280.950186 115.447116 \nL 280.96921 114.234683 \nL 281.007258 116.26133 \nL 281.06433 115.038231 \nL 281.121401 114.337793 \nL 281.178473 116.02311 \nL 281.216521 114.597346 \nL 281.235545 116.26133 \nL 281.292617 115.297784 \nL 281.311641 115.841779 \nL 281.387736 114.856899 \nL 281.40676 115.440005 \nL 281.425784 115.724446 \nL 281.463832 114.970676 \nL 281.482856 115.500449 \nL 281.50188 114.58668 \nL 281.539928 116.001777 \nL 281.577975 115.68178 \nL 281.654071 114.632902 \nL 281.673095 115.667558 \nL 281.711143 115.201785 \nL 281.749191 116.129776 \nL 281.787238 114.647124 \nL 281.863334 115.944889 \nL 281.93943 115.027564 \nL 281.977478 115.265784 \nL 281.996501 115.99111 \nL 282.015525 114.579569 \nL 282.091621 115.752891 \nL 282.110645 114.7929 \nL 282.186741 115.983999 \nL 282.205765 115.084453 \nL 282.28186 115.688891 \nL 282.243812 114.750234 \nL 282.319908 115.141341 \nL 282.396004 114.273794 \nL 282.357956 116.030221 \nL 282.415028 115.233785 \nL 282.434052 116.403551 \nL 282.472099 113.84002 \nL 282.529171 115.440005 \nL 282.567219 114.38046 \nL 282.586243 116.037332 \nL 282.643315 115.080897 \nL 282.662339 116.197331 \nL 282.700386 114.608013 \nL 282.757458 115.486226 \nL 282.833554 116.719992 \nL 282.871602 114.373349 \nL 282.966721 116.239997 \nL 282.947697 114.312905 \nL 282.985745 115.223118 \nL 283.023793 114.828455 \nL 283.061841 115.770668 \nL 283.099889 115.802668 \nL 283.15696 114.362682 \nL 283.271104 116.311107 \nL 283.385247 114.568902 \nL 283.404271 116.165331 \nL 283.442319 114.487125 \nL 283.499391 115.326228 \nL 283.537439 114.718234 \nL 283.556463 115.92 \nL 283.613534 114.796455 \nL 283.727678 116.101332 \nL 283.841821 114.622235 \nL 283.955965 116.286219 \nL 283.994013 114.327127 \nL 284.070108 114.906677 \nL 284.146204 114.704012 \nL 284.184252 116.193775 \nL 284.203276 114.234683 \nL 284.241324 116.22933 \nL 284.298395 115.116452 \nL 284.355467 114.611568 \nL 284.412539 116.46755 \nL 284.450587 114.220461 \nL 284.526682 114.636457 \nL 284.583754 114.611568 \nL 284.640826 115.788446 \nL 284.65985 114.753789 \nL 284.697898 115.820445 \nL 284.754969 114.981343 \nL 284.773993 116.168886 \nL 284.812041 114.444459 \nL 284.869113 116.065776 \nL 284.888137 114.529791 \nL 284.983256 115.073786 \nL 285.00228 114.942232 \nL 285.021304 115.059564 \nL 285.040328 115.880889 \nL 285.0974 114.945787 \nL 285.135448 115.447116 \nL 285.173496 115.50756 \nL 285.211543 114.981343 \nL 285.230567 115.653336 \nL 285.268615 115.013342 \nL 285.325687 116.047999 \nL 285.363735 115.002676 \nL 285.382759 115.251562 \nL 285.401783 115.034675 \nL 285.420806 116.019555 \nL 285.43983 115.176896 \nL 285.477878 114.68979 \nL 285.53495 116.094221 \nL 285.592022 116.168886 \nL 285.649093 114.124462 \nL 285.687141 116.627549 \nL 285.782261 115.639114 \nL 285.801285 115.048897 \nL 285.839333 115.685336 \nL 285.896404 115.276451 \nL 285.934452 115.002676 \nL 286.010548 115.973333 \nL 286.124691 114.7609 \nL 286.181763 115.877334 \nL 286.200787 114.661346 \nL 286.238835 115.777779 \nL 286.31493 114.974232 \nL 286.352978 115.539559 \nL 286.391026 114.842677 \nL 286.429074 115.642669 \nL 286.467122 115.16623 \nL 286.486146 115.208896 \nL 286.524194 115.937778 \nL 286.543217 114.800011 \nL 286.600289 115.820445 \nL 286.638337 114.888899 \nL 286.714433 114.920899 \nL 286.733457 116.108443 \nL 286.771504 114.832011 \nL 286.828576 115.592892 \nL 286.8476 115.056008 \nL 286.94272 115.347561 \nL 286.980768 115.738668 \nL 286.999791 115.50756 \nL 287.094911 114.853344 \nL 287.075887 115.809779 \nL 287.113935 115.194674 \nL 287.171007 115.738668 \nL 287.190031 115.301339 \nL 287.209055 114.949343 \nL 287.247102 115.774224 \nL 287.304174 115.120008 \nL 287.323198 115.059564 \nL 287.342222 115.358228 \nL 287.361246 115.169785 \nL 287.38027 115.436449 \nL 287.475389 115.248007 \nL 287.494413 115.390227 \nL 287.551485 115.080897 \nL 287.589533 115.280006 \nL 287.627581 115.696002 \nL 287.703676 115.013342 \nL 287.836844 115.781335 \nL 287.855868 115.080897 \nL 287.950987 115.425783 \nL 288.008059 115.745779 \nL 288.027083 115.052453 \nL 288.065131 115.61067 \nL 288.141226 115.521782 \nL 288.16025 115.10223 \nL 288.217322 115.418672 \nL 288.236346 115.916444 \nL 288.274394 115.03112 \nL 288.331466 115.550226 \nL 288.369513 115.056008 \nL 288.407561 115.703113 \nL 288.445609 115.347561 \nL 288.464633 115.464893 \nL 288.483657 115.052453 \nL 288.521705 115.30845 \nL 288.559753 115.809779 \nL 288.635848 115.045342 \nL 288.654872 115.589337 \nL 288.749992 115.557337 \nL 288.826087 114.888899 \nL 288.864135 115.408005 \nL 288.940231 115.123563 \nL 288.902183 115.553781 \nL 288.997303 115.144896 \nL 289.016327 115.144896 \nL 289.092422 115.06312 \nL 289.149494 115.511115 \nL 289.187542 115.041786 \nL 289.206566 115.568003 \nL 289.282661 115.10223 \nL 289.301685 115.617781 \nL 289.396805 115.400894 \nL 289.453877 115.159119 \nL 289.510948 115.585781 \nL 289.529972 115.080897 \nL 289.625092 115.187563 \nL 289.66314 115.496893 \nL 289.701188 115.098675 \nL 289.739235 115.397338 \nL 289.815331 115.464893 \nL 289.834355 114.945787 \nL 289.948498 115.671114 \nL 290.10069 115.127119 \nL 290.157762 115.61067 \nL 290.176785 115.105786 \nL 290.214833 115.57867 \nL 290.271905 115.173341 \nL 290.348001 115.383116 \nL 290.405072 115.532448 \nL 290.386049 115.333339 \nL 290.424096 115.454227 \nL 290.44312 115.194674 \nL 290.462144 115.564448 \nL 290.53824 115.251562 \nL 290.576288 115.301339 \nL 290.595312 115.20534 \nL 290.633359 115.61067 \nL 290.709455 115.450671 \nL 290.804575 115.120008 \nL 290.823599 115.255118 \nL 290.918718 115.61067 \nL 290.899694 115.009787 \nL 290.937742 115.436449 \nL 290.994814 114.867566 \nL 290.97579 115.57867 \nL 291.07091 115.265784 \nL 291.127981 115.386672 \nL 291.166029 115.173341 \nL 291.185053 115.57867 \nL 291.204077 115.109341 \nL 291.280173 115.244451 \nL 291.299197 114.910232 \nL 291.31822 115.660447 \nL 291.375292 115.425783 \nL 291.41334 115.436449 \nL 291.470412 115.272895 \nL 291.546507 115.518226 \nL 291.50846 115.066675 \nL 291.584555 115.315561 \nL 291.622603 115.304895 \nL 291.641627 115.351117 \nL 291.717723 115.614225 \nL 291.679675 115.326228 \nL 291.736747 115.361783 \nL 291.774794 115.440005 \nL 291.85089 115.312006 \nL 291.869914 115.667558 \nL 291.907962 114.988454 \nL 291.94601 115.258673 \nL 292.022105 115.500449 \nL 291.984058 115.201785 \nL 292.060153 115.454227 \nL 292.079177 115.112897 \nL 292.174297 115.393783 \nL 292.193321 115.461338 \nL 292.212345 115.144896 \nL 292.231368 115.059564 \nL 292.250392 115.26934 \nL 292.269416 115.422227 \nL 292.307464 115.116452 \nL 292.345512 115.265784 \nL 292.402584 115.393783 \nL 292.459655 115.159119 \nL 292.497703 115.408005 \nL 292.516727 115.120008 \nL 292.573799 115.361783 \nL 292.611847 115.276451 \nL 292.630871 115.767113 \nL 292.706966 115.208896 \nL 292.72599 115.450671 \nL 292.783062 115.230229 \nL 292.859158 115.37245 \nL 292.897206 115.472004 \nL 292.916229 115.137785 \nL 292.954277 115.575114 \nL 293.011349 115.194674 \nL 293.144516 115.418672 \nL 293.201588 115.482671 \nL 293.25866 115.123563 \nL 293.372803 115.351117 \nL 293.410851 115.457782 \nL 293.486947 115.258673 \nL 293.524995 115.383116 \nL 293.582067 115.194674 \nL 293.620114 115.383116 \nL 293.658162 115.244451 \nL 293.69621 115.564448 \nL 293.810353 114.995565 \nL 293.867425 115.585781 \nL 293.924497 115.436449 \nL 293.943521 115.112897 \nL 294.03864 115.194674 \nL 294.152784 115.543115 \nL 294.190832 115.255118 \nL 294.285951 115.290673 \nL 294.381071 115.472004 \nL 294.343023 115.194674 \nL 294.400095 115.30845 \nL 294.457167 115.422227 \nL 294.438143 115.098675 \nL 294.476191 115.297784 \nL 294.495214 115.184007 \nL 294.514238 115.500449 \nL 294.590334 115.216007 \nL 294.609358 115.550226 \nL 294.647406 115.116452 \nL 294.704478 115.429338 \nL 294.742525 115.130674 \nL 294.761549 115.47556 \nL 294.799597 115.294228 \nL 294.856669 115.532448 \nL 294.894717 115.16623 \nL 294.913741 115.40445 \nL 295.00886 115.265784 \nL 295.027884 115.411561 \nL 295.046908 115.468449 \nL 295.10398 115.34045 \nL 295.199099 115.073786 \nL 295.161052 115.436449 \nL 295.218123 115.34045 \nL 295.237147 115.50756 \nL 295.313243 115.454227 \nL 295.408362 115.105786 \nL 295.370315 115.500449 \nL 295.427386 115.322673 \nL 295.503482 115.454227 \nL 295.560554 115.276451 \nL 295.598602 115.592892 \nL 295.712745 115.077342 \nL 295.731769 115.262229 \nL 295.788841 115.440005 \nL 295.769817 115.130674 \nL 295.826889 115.351117 \nL 295.88396 115.173341 \nL 295.941032 115.223118 \nL 296.036152 115.457782 \nL 296.093223 115.400894 \nL 296.169319 115.152008 \nL 296.188343 115.432894 \nL 296.207367 115.418672 \nL 296.226391 115.116452 \nL 296.245415 115.489782 \nL 296.32151 115.347561 \nL 296.397606 115.244451 \nL 296.454678 115.603559 \nL 296.51175 115.486226 \nL 296.587845 115.607114 \nL 296.625893 115.233785 \nL 296.682965 115.447116 \nL 296.740037 115.383116 \nL 296.759061 115.386672 \nL 296.778084 115.280006 \nL 296.835156 115.376005 \nL 296.911252 115.176896 \nL 297.006371 115.450671 \nL 297.044419 115.386672 \nL 297.177587 115.230229 \nL 297.196611 115.432894 \nL 297.29173 115.40445 \nL 297.310754 115.194674 \nL 297.38685 115.425783 \nL 297.405874 115.329784 \nL 297.462945 115.233785 \nL 297.481969 115.319117 \nL 297.539041 115.077342 \nL 297.615137 115.440005 \nL 297.634161 115.23734 \nL 297.72928 115.258673 \nL 297.862448 115.50756 \nL 297.881472 115.248007 \nL 297.976591 115.351117 \nL 298.071711 115.333339 \nL 298.033663 115.386672 \nL 298.090735 115.358228 \nL 298.433165 115.351117 \nL 298.471213 115.219562 \nL 298.547309 115.322673 \nL 298.566333 115.315561 \nL 298.585356 115.411561 \nL 298.60438 115.436449 \nL 298.623404 115.208896 \nL 298.718524 115.294228 \nL 298.851691 115.397338 \nL 298.870715 115.365339 \nL 298.889739 115.34045 \nL 298.927787 115.440005 \nL 298.965835 115.418672 \nL 299.251194 115.276451 \nL 299.327289 115.26934 \nL 299.403385 115.422227 \nL 299.422409 115.30845 \nL 299.460457 115.20534 \nL 299.498504 115.358228 \nL 299.517528 115.322673 \nL 299.612648 115.40445 \nL 299.5746 115.276451 \nL 299.650696 115.383116 \nL 299.66972 115.379561 \nL 299.688744 115.198229 \nL 299.783863 115.276451 \nL 299.859959 115.425783 \nL 299.898007 115.315561 \nL 299.917031 115.422227 \nL 299.974102 115.280006 \nL 300.01215 115.390227 \nL 300.031174 115.244451 \nL 300.050198 115.425783 \nL 300.126294 115.329784 \nL 300.164342 115.287117 \nL 300.202389 115.429338 \nL 300.240437 115.13423 \nL 300.316533 115.344006 \nL 300.373605 115.379561 \nL 300.4497 115.287117 \nL 300.468724 115.386672 \nL 300.525796 115.255118 \nL 300.563844 115.354672 \nL 300.697011 115.280006 \nL 300.716035 115.336895 \nL 300.773107 115.251562 \nL 300.849203 115.429338 \nL 300.925298 115.37245 \nL 300.944322 115.528893 \nL 300.963346 115.297784 \nL 301.020418 115.30845 \nL 301.07749 115.383116 \nL 301.134561 115.319117 \nL 301.229681 115.301339 \nL 301.248705 115.326228 \nL 301.305777 115.290673 \nL 301.381872 115.400894 \nL 301.51504 115.226673 \nL 301.572111 115.180452 \nL 301.648207 115.347561 \nL 301.667231 115.258673 \nL 301.705279 115.422227 \nL 301.76235 115.329784 \nL 301.819422 115.432894 \nL 301.85747 115.383116 \nL 301.95259 115.265784 \nL 301.971614 115.287117 \nL 302.047709 115.191118 \nL 302.104781 115.393783 \nL 302.142829 115.219562 \nL 302.218924 115.233785 \nL 302.314044 115.212451 \nL 302.352092 115.489782 \nL 302.485259 115.30845 \nL 302.82769 115.347561 \nL 302.903785 115.47556 \nL 302.865738 115.297784 \nL 302.941833 115.400894 \nL 302.998905 115.489782 \nL 303.055977 115.26934 \nL 303.17012 115.393783 \nL 303.246216 115.262229 \nL 303.284264 115.347561 \nL 303.341336 115.230229 \nL 303.360359 115.358228 \nL 303.455479 115.422227 \nL 303.398407 115.280006 \nL 303.474503 115.368894 \nL 303.550599 115.422227 \nL 303.626694 115.304895 \nL 303.645718 115.393783 \nL 303.70279 115.251562 \nL 303.79791 115.248007 \nL 303.740838 115.315561 \nL 303.816933 115.265784 \nL 303.854981 115.230229 \nL 303.931077 115.379561 \nL 304.04522 115.294228 \nL 303.988149 115.457782 \nL 304.064244 115.365339 \nL 304.254484 115.365339 \nL 304.292531 115.301339 \nL 304.349603 115.34045 \nL 304.387651 115.386672 \nL 304.444723 115.344006 \nL 304.463747 115.265784 \nL 304.501794 115.415116 \nL 304.520818 115.358228 \nL 304.539842 115.436449 \nL 304.596914 115.240896 \nL 304.615938 115.283562 \nL 304.653986 115.223118 \nL 304.711058 115.312006 \nL 304.730081 115.208896 \nL 304.806177 115.290673 \nL 304.920321 115.429338 \nL 304.939345 115.315561 \nL 304.996416 115.390227 \nL 305.053488 115.319117 \nL 305.205679 115.23734 \nL 305.357871 115.425783 \nL 305.376895 115.415116 \nL 305.529086 115.194674 \nL 305.414942 115.493338 \nL 305.567134 115.244451 \nL 305.681277 115.176896 \nL 305.795421 115.418672 \nL 305.814445 115.319117 \nL 305.909564 115.386672 \nL 305.947612 115.315561 \nL 306.023708 115.376005 \nL 306.061756 115.248007 \nL 306.175899 115.354672 \nL 306.213947 115.315561 \nL 306.32809 115.450671 \nL 306.442234 115.30845 \nL 306.499306 115.400894 \nL 306.480282 115.287117 \nL 306.556377 115.329784 \nL 308.325602 115.344006 \nL 308.344626 115.176896 \nL 308.382673 115.376005 \nL 308.420721 115.301339 \nL 308.496817 115.376005 \nL 308.534865 115.358228 \nL 308.70608 115.208896 \nL 308.820223 115.358228 \nL 308.915343 115.280006 \nL 308.934367 115.351117 \nL 308.991439 115.415116 \nL 309.029487 115.351117 \nL 309.105582 115.411561 \nL 309.124606 115.319117 \nL 309.181678 115.304895 \nL 309.200702 115.397338 \nL 309.219726 115.230229 \nL 309.314845 115.304895 \nL 309.428989 115.361783 \nL 309.505084 115.457782 \nL 309.543132 115.319117 \nL 309.562156 115.461338 \nL 309.600204 115.272895 \nL 309.657276 115.354672 \nL 309.790443 115.258673 \nL 309.809467 115.322673 \nL 309.847515 115.216007 \nL 309.904587 115.418672 \nL 309.923611 115.244451 \nL 310.01873 115.336895 \nL 310.056778 115.283562 \nL 310.132874 115.400894 \nL 310.266041 115.223118 \nL 310.285065 115.415116 \nL 310.380185 115.354672 \nL 310.475304 115.34045 \nL 310.494328 115.358228 \nL 310.570424 115.411561 \nL 310.589448 115.34045 \nL 310.703591 115.248007 \nL 310.627495 115.368894 \nL 310.722615 115.265784 \nL 310.779687 115.304895 \nL 310.798711 115.233785 \nL 310.912854 115.351117 \nL 310.931878 115.258673 \nL 310.950902 115.379561 \nL 311.026998 115.329784 \nL 311.084069 115.393783 \nL 311.065046 115.26934 \nL 311.141141 115.351117 \nL 311.236261 115.276451 \nL 311.255285 115.319117 \nL 311.388452 115.354672 \nL 311.4265 115.411561 \nL 311.464548 115.37245 \nL 311.52162 115.422227 \nL 311.502596 115.283562 \nL 311.540643 115.344006 \nL 311.559667 115.297784 \nL 311.616739 115.436449 \nL 311.635763 115.34045 \nL 311.654787 115.415116 \nL 311.711859 115.376005 \nL 311.730883 115.233785 \nL 311.826002 115.336895 \nL 313.214748 115.240896 \nL 313.233772 115.201785 \nL 313.252796 115.418672 \nL 313.347916 115.397338 \nL 313.404987 115.223118 \nL 313.385963 115.486226 \nL 313.462059 115.326228 \nL 313.500107 115.226673 \nL 313.519131 115.440005 \nL 313.595226 115.173341 \nL 313.633274 115.212451 \nL 313.70937 115.397338 \nL 313.747418 115.379561 \nL 313.861561 115.319117 \nL 313.918633 115.422227 \nL 313.956681 115.248007 \nL 313.975705 115.365339 \nL 314.089848 115.265784 \nL 314.108872 115.326228 \nL 314.203992 115.304895 \nL 314.24204 115.262229 \nL 314.318135 115.368894 \nL 314.413255 115.219562 \nL 314.356183 115.457782 \nL 314.432279 115.326228 \nL 314.508374 115.180452 \nL 314.565446 115.400894 \nL 314.622518 115.354672 \nL 314.641542 115.294228 \nL 314.660566 115.440005 \nL 314.717637 115.40445 \nL 314.812757 115.436449 \nL 314.926901 115.26934 \nL 314.945924 115.432894 \nL 315.02202 115.294228 \nL 315.041044 115.226673 \nL 315.098116 115.255118 \nL 315.193235 115.411561 \nL 315.212259 115.358228 \nL 315.307379 115.198229 \nL 315.345427 115.223118 \nL 315.45957 115.365339 \nL 315.478594 115.208896 \nL 315.535666 115.400894 \nL 315.55469 115.329784 \nL 315.592738 115.486226 \nL 315.668833 115.429338 \nL 315.763953 115.468449 \nL 315.782977 115.287117 \nL 315.802001 115.486226 \nL 315.89712 115.422227 \nL 315.916144 115.248007 \nL 315.935168 115.436449 \nL 316.011264 115.30845 \nL 316.030288 115.425783 \nL 316.049312 115.251562 \nL 316.106383 115.361783 \nL 316.182479 115.312006 \nL 316.201503 115.454227 \nL 316.220527 115.262229 \nL 316.277599 115.319117 \nL 316.296623 115.244451 \nL 316.372718 115.37245 \nL 316.391742 115.287117 \nL 316.448814 115.397338 \nL 316.42979 115.276451 \nL 316.505886 115.365339 \nL 316.562957 115.169785 \nL 316.581981 115.415116 \nL 316.620029 115.262229 \nL 316.639053 115.44356 \nL 316.658077 115.244451 \nL 316.715149 115.301339 \nL 316.829292 115.262229 \nL 316.96246 115.393783 \nL 317.323914 115.240896 \nL 317.438058 115.447116 \nL 317.457081 115.23734 \nL 317.476105 115.543115 \nL 317.552201 115.34045 \nL 317.609273 115.408005 \nL 317.628297 115.216007 \nL 317.74244 115.450671 \nL 317.894631 115.361783 \nL 317.913655 115.432894 \nL 317.970727 115.319117 \nL 317.989751 115.383116 \nL 318.065847 115.194674 \nL 318.122918 115.272895 \nL 318.218038 115.397338 \nL 318.294134 115.223118 \nL 318.313158 115.440005 \nL 318.332182 115.283562 \nL 318.370229 115.397338 \nL 318.446325 115.319117 \nL 318.522421 115.26934 \nL 318.560469 115.336895 \nL 318.71266 115.365339 \nL 318.883875 115.34045 \nL 318.940947 115.233785 \nL 318.921923 115.411561 \nL 318.998019 115.312006 \nL 319.05509 115.422227 \nL 319.036066 115.20534 \nL 319.112162 115.336895 \nL 319.169234 115.23734 \nL 319.188258 115.486226 \nL 319.207282 115.244451 \nL 319.302401 115.319117 \nL 319.340449 115.187563 \nL 319.378497 115.276451 \nL 319.397521 115.440005 \nL 319.416545 115.230229 \nL 319.49264 115.418672 \nL 319.58776 115.283562 \nL 319.606784 115.347561 \nL 319.720927 115.390227 \nL 319.739951 115.319117 \nL 319.797023 115.322673 \nL 319.816047 115.379561 \nL 319.835071 115.432894 \nL 319.873119 115.226673 \nL 319.892143 115.408005 \nL 319.968238 115.23734 \nL 320.006286 115.294228 \nL 320.02531 115.450671 \nL 320.12043 115.358228 \nL 320.139454 115.233785 \nL 320.196525 115.408005 \nL 320.234573 115.276451 \nL 320.291645 115.440005 \nL 320.272621 115.258673 \nL 320.348717 115.290673 \nL 320.405788 115.180452 \nL 320.424812 115.454227 \nL 320.538956 115.226673 \nL 320.55798 115.383116 \nL 320.577004 115.216007 \nL 320.653099 115.287117 \nL 320.99553 115.30845 \nL 321.147721 115.333339 \nL 321.223817 115.393783 \nL 321.242841 115.233785 \nL 321.299913 115.432894 \nL 321.33796 115.255118 \nL 321.356984 115.418672 \nL 321.376008 115.148452 \nL 321.452104 115.383116 \nL 321.471128 115.187563 \nL 321.547223 115.251562 \nL 321.566247 115.40445 \nL 321.642343 115.216007 \nL 321.661367 115.329784 \nL 321.699415 115.240896 \nL 321.737463 115.365339 \nL 321.77551 115.304895 \nL 321.87063 115.354672 \nL 321.889654 115.248007 \nL 321.908678 115.365339 \nL 321.984773 115.276451 \nL 322.003797 115.472004 \nL 322.022821 115.26934 \nL 322.098917 115.429338 \nL 322.117941 115.30845 \nL 322.175013 115.454227 \nL 322.21306 115.376005 \nL 322.384276 115.301339 \nL 322.4033 115.347561 \nL 322.479395 115.44356 \nL 322.498419 115.265784 \nL 322.593539 115.283562 \nL 322.688658 115.432894 \nL 322.707682 115.322673 \nL 322.74573 115.40445 \nL 322.821826 115.294228 \nL 322.935969 115.432894 \nL 323.050113 115.344006 \nL 323.088161 115.418672 \nL 323.107185 115.297784 \nL 323.145232 115.30845 \nL 323.2784 115.244451 \nL 323.354495 115.376005 \nL 323.392543 115.333339 \nL 323.468639 115.283562 \nL 323.487663 115.422227 \nL 323.506687 115.233785 \nL 323.582782 115.408005 \nL 323.696926 115.219562 \nL 323.753998 115.390227 \nL 323.811069 115.379561 \nL 323.868141 115.258673 \nL 323.925213 115.329784 \nL 323.982285 115.379561 \nL 323.963261 115.255118 \nL 324.039356 115.329784 \nL 324.172524 115.30845 \nL 324.24862 115.393783 \nL 324.267643 115.333339 \nL 324.343739 115.304895 \nL 324.324715 115.379561 \nL 324.362763 115.393783 \nL 324.514954 115.276451 \nL 324.533978 115.297784 \nL 324.59105 115.422227 \nL 324.572026 115.23734 \nL 324.648122 115.365339 \nL 324.68617 115.450671 \nL 324.743241 115.248007 \nL 324.857385 115.489782 \nL 324.952504 115.233785 \nL 324.990552 115.358228 \nL 325.009576 115.26934 \nL 325.0286 115.464893 \nL 325.085672 115.312006 \nL 325.199815 115.432894 \nL 325.256887 115.294228 \nL 325.237863 115.464893 \nL 325.313959 115.336895 \nL 325.332983 115.418672 \nL 325.352007 115.23734 \nL 325.390055 115.248007 \nL 325.523222 115.219562 \nL 325.656389 115.358228 \nL 325.865652 115.251562 \nL 326.017844 115.390227 \nL 326.074915 115.244451 \nL 326.131987 115.287117 \nL 326.151011 115.408005 \nL 326.170035 115.280006 \nL 326.246131 115.34045 \nL 326.34125 115.173341 \nL 326.360274 115.276451 \nL 326.398322 115.240896 \nL 326.512466 115.400894 \nL 326.664657 115.276451 \nL 326.702705 115.425783 \nL 326.721729 115.212451 \nL 326.797824 115.326228 \nL 326.854896 115.240896 \nL 326.87392 115.461338 \nL 326.892944 115.219562 \nL 326.96904 115.418672 \nL 327.026111 115.297784 \nL 327.007087 115.500449 \nL 327.102207 115.344006 \nL 327.254398 115.383116 \nL 327.292446 115.479115 \nL 327.368542 115.294228 \nL 327.463661 115.386672 \nL 327.577805 115.251562 \nL 327.74902 115.411561 \nL 327.825116 115.319117 \nL 327.863164 115.376005 \nL 327.977307 115.397338 \nL 328.091451 115.297784 \nL 328.167546 115.393783 \nL 328.205594 115.329784 \nL 328.262666 115.447116 \nL 328.319738 115.390227 \nL 328.395833 115.47556 \nL 328.414857 115.26934 \nL 328.433881 115.429338 \nL 328.509977 115.162674 \nL 328.529001 115.351117 \nL 328.548025 115.088008 \nL 328.643144 115.30845 \nL 328.700216 115.40445 \nL 328.71924 115.230229 \nL 328.757288 115.361783 \nL 328.776312 115.255118 \nL 328.871431 115.304895 \nL 329.06167 115.297784 \nL 329.213862 115.468449 \nL 329.480196 115.290673 \nL 329.537268 115.472004 \nL 329.518244 115.191118 \nL 329.59434 115.376005 \nL 329.651412 115.201785 \nL 329.632388 115.397338 \nL 329.708483 115.312006 \nL 329.727507 115.390227 \nL 329.784579 115.219562 \nL 329.803603 115.319117 \nL 329.917747 115.226673 \nL 329.955794 115.30845 \nL 330.012866 115.393783 \nL 330.069938 115.361783 \nL 330.146034 115.500449 \nL 330.165057 115.287117 \nL 330.260177 115.265784 \nL 330.279201 115.464893 \nL 330.298225 115.23734 \nL 330.393344 115.255118 \nL 330.412368 115.447116 \nL 330.431392 115.208896 \nL 330.507488 115.312006 \nL 330.602608 115.258673 \nL 330.545536 115.336895 \nL 330.640655 115.287117 \nL 330.697727 115.383116 \nL 330.678703 115.226673 \nL 330.735775 115.361783 \nL 330.811871 115.212451 \nL 330.792847 115.44356 \nL 330.849918 115.287117 \nL 330.964062 115.479115 \nL 330.983086 115.283562 \nL 331.078205 115.379561 \nL 331.116253 115.297784 \nL 331.173325 115.432894 \nL 331.287469 115.336895 \nL 331.325516 115.276451 \nL 331.420636 115.461338 \nL 331.43966 115.294228 \nL 331.515756 115.50756 \nL 331.534779 115.319117 \nL 331.591851 115.486226 \nL 331.572827 115.26934 \nL 331.629899 115.319117 \nL 331.744043 115.169785 \nL 331.858186 115.411561 \nL 331.953306 115.351117 \nL 331.97233 115.415116 \nL 332.029401 115.297784 \nL 332.048425 115.390227 \nL 332.162569 115.194674 \nL 332.181593 115.322673 \nL 332.276712 115.23734 \nL 332.562071 115.400894 \nL 332.619143 115.201785 \nL 332.695238 115.276451 \nL 332.733286 115.315561 \nL 332.75231 115.251562 \nL 332.771334 115.429338 \nL 332.866454 115.336895 \nL 332.999621 115.283562 \nL 333.018645 115.450671 \nL 333.037669 115.276451 \nL 333.113765 115.422227 \nL 333.208884 115.30845 \nL 333.227908 115.479115 \nL 333.304004 115.26934 \nL 333.323028 115.457782 \nL 333.437171 115.276451 \nL 333.551315 115.386672 \nL 333.646434 115.23734 \nL 333.62741 115.450671 \nL 333.665458 115.365339 \nL 333.779602 115.20534 \nL 333.836673 115.418672 \nL 333.817649 115.173341 \nL 333.893745 115.326228 \nL 333.950817 115.13423 \nL 333.931793 115.408005 \nL 333.988865 115.184007 \nL 334.103008 115.383116 \nL 334.122032 115.208896 \nL 334.198128 115.457782 \nL 334.217152 115.304895 \nL 334.236176 115.429338 \nL 334.331295 115.34045 \nL 334.426415 115.326228 \nL 334.445439 115.354672 \nL 334.578606 115.432894 \nL 334.730797 115.379561 \nL 334.806893 115.436449 \nL 334.825917 115.354672 \nL 334.94006 115.251562 \nL 334.959084 115.287117 \nL 335.054204 115.354672 \nL 334.997132 115.230229 \nL 335.073228 115.301339 \nL 335.168347 115.184007 \nL 335.111276 115.354672 \nL 335.187371 115.287117 \nL 335.339563 115.251562 \nL 335.453706 115.361783 \nL 335.47273 115.233785 \nL 335.491754 115.376005 \nL 335.548826 115.290673 \nL 335.56785 115.397338 \nL 335.624921 115.351117 \nL 335.643945 115.155563 \nL 335.662969 115.44356 \nL 335.720041 115.294228 \nL 335.777113 115.230229 \nL 335.796137 115.464893 \nL 335.815161 115.162674 \nL 335.834185 115.496893 \nL 335.91028 115.230229 \nL 335.929304 115.536004 \nL 335.948328 115.187563 \nL 336.024424 115.422227 \nL 336.119543 115.255118 \nL 336.138567 115.468449 \nL 336.157591 115.201785 \nL 336.233687 115.429338 \nL 336.252711 115.304895 \nL 336.34783 115.400894 \nL 336.461974 115.344006 \nL 336.480998 115.450671 \nL 336.576117 115.429338 \nL 336.728309 115.280006 \nL 336.766356 115.265784 \nL 336.842452 115.383116 \nL 336.956596 115.212451 \nL 337.051715 115.141341 \nL 337.070739 115.304895 \nL 337.089763 115.120008 \nL 337.108787 115.344006 \nL 337.184883 115.155563 \nL 337.241954 115.390227 \nL 337.22293 115.148452 \nL 337.299026 115.376005 \nL 337.31805 115.194674 \nL 337.337074 115.454227 \nL 337.41317 115.287117 \nL 337.432193 115.450671 \nL 337.489265 115.272895 \nL 337.508289 115.319117 \nL 337.565361 115.376005 \nL 337.584385 115.290673 \nL 337.603409 115.432894 \nL 337.698528 115.368894 \nL 337.812672 115.521782 \nL 337.869744 115.304895 \nL 337.85072 115.582226 \nL 337.926815 115.358228 \nL 337.983887 115.536004 \nL 338.002911 115.248007 \nL 338.021935 115.514671 \nL 338.098031 115.255118 \nL 338.136078 115.287117 \nL 338.19315 115.368894 \nL 338.212174 115.262229 \nL 338.250222 115.333339 \nL 338.383389 115.244451 \nL 338.402413 115.315561 \nL 338.440461 115.208896 \nL 338.497533 115.248007 \nL 338.573628 115.333339 \nL 338.592652 115.272895 \nL 338.649724 115.130674 \nL 338.6307 115.390227 \nL 338.706796 115.208896 \nL 338.72582 115.411561 \nL 338.744844 115.184007 \nL 338.820939 115.280006 \nL 338.916059 115.262229 \nL 338.954107 115.219562 \nL 339.030202 115.40445 \nL 339.049226 115.297784 \nL 339.144346 115.333339 \nL 339.182394 115.315561 \nL 339.258489 115.40445 \nL 339.353609 115.450671 \nL 339.372633 115.344006 \nL 339.486776 115.500449 \nL 339.524824 115.521782 \nL 339.60092 115.34045 \nL 339.657992 115.496893 \nL 339.638968 115.312006 \nL 339.715063 115.40445 \nL 339.772135 115.255118 \nL 339.810183 115.276451 \nL 339.829207 115.432894 \nL 339.905303 115.230229 \nL 339.924327 115.333339 \nL 340.057494 115.155563 \nL 340.13359 115.468449 \nL 340.152614 115.116452 \nL 340.171637 115.358228 \nL 340.209685 115.191118 \nL 340.228709 115.390227 \nL 340.285781 115.290673 \nL 340.342853 115.344006 \nL 340.323829 115.201785 \nL 340.361877 115.230229 \nL 340.380901 115.219562 \nL 340.437972 115.454227 \nL 340.418948 115.20534 \nL 340.495044 115.358228 \nL 340.552116 115.16623 \nL 340.533092 115.432894 \nL 340.609188 115.23734 \nL 340.628211 115.511115 \nL 340.647235 115.201785 \nL 340.723331 115.425783 \nL 340.780403 115.301339 \nL 340.799427 115.504004 \nL 340.818451 115.351117 \nL 340.894546 115.464893 \nL 340.932594 115.432894 \nL 341.065762 115.333339 \nL 341.084785 115.408005 \nL 341.141857 115.393783 \nL 341.198929 115.248007 \nL 341.217953 115.436449 \nL 341.256001 115.37245 \nL 341.313072 115.408005 \nL 341.294049 115.251562 \nL 341.35112 115.368894 \nL 341.427216 115.244451 \nL 341.484288 115.283562 \nL 341.503312 115.344006 \nL 341.522335 115.212451 \nL 341.560383 115.233785 \nL 341.579407 115.201785 \nL 341.598431 115.354672 \nL 341.617455 115.233785 \nL 341.636479 115.358228 \nL 341.712575 115.255118 \nL 341.78867 115.198229 \nL 341.807694 115.482671 \nL 341.826718 115.184007 \nL 341.902814 115.472004 \nL 341.921838 115.251562 \nL 342.016957 115.326228 \nL 342.055005 115.301339 \nL 342.131101 115.418672 \nL 342.207196 115.255118 \nL 342.264268 115.312006 \nL 342.397436 115.390227 \nL 342.549627 115.376005 \nL 342.644747 115.301339 \nL 342.66377 115.500449 \nL 342.739866 115.351117 \nL 342.796938 115.301339 \nL 342.777914 115.454227 \nL 342.815962 115.336895 \nL 342.873034 115.44356 \nL 342.85401 115.233785 \nL 342.930105 115.379561 \nL 342.987177 115.223118 \nL 342.968153 115.393783 \nL 343.044249 115.304895 \nL 343.158392 115.162674 \nL 343.177416 115.436449 \nL 343.272536 115.411561 \nL 343.29156 115.226673 \nL 343.310584 115.436449 \nL 343.386679 115.26934 \nL 343.443751 115.244451 \nL 343.519847 115.415116 \nL 343.557895 115.26934 \nL 343.63399 115.283562 \nL 343.748134 115.347561 \nL 343.843253 115.276451 \nL 343.824229 115.415116 \nL 343.862277 115.312006 \nL 343.919349 115.386672 \nL 343.900325 115.248007 \nL 343.957397 115.344006 \nL 343.976421 115.265784 \nL 343.995445 115.379561 \nL 344.033492 115.326228 \nL 344.052516 115.479115 \nL 344.07154 115.301339 \nL 344.147636 115.411561 \nL 344.185684 115.50756 \nL 344.261779 115.276451 \nL 344.337875 115.376005 \nL 344.394947 115.347561 \nL 344.490066 115.276451 \nL 344.50909 115.333339 \nL 344.528114 115.393783 \nL 344.547138 115.255118 \nL 344.60421 115.265784 \nL 344.69933 115.329784 \nL 344.737377 115.393783 \nL 344.813473 115.148452 \nL 344.832497 115.329784 \nL 344.927617 115.294228 \nL 344.965664 115.201785 \nL 345.022736 115.290673 \nL 345.060784 115.240896 \nL 345.155904 115.440005 \nL 345.174927 115.265784 \nL 345.270047 115.390227 \nL 345.346143 115.230229 \nL 345.365167 115.464893 \nL 345.38419 115.354672 \nL 345.47931 115.287117 \nL 345.498334 115.464893 \nL 345.536382 115.493338 \nL 345.612477 115.365339 \nL 345.669549 115.479115 \nL 345.650525 115.294228 \nL 345.707597 115.368894 \nL 345.726621 115.333339 \nL 345.745645 115.425783 \nL 345.783693 115.379561 \nL 345.802717 115.496893 \nL 345.821741 115.255118 \nL 345.897836 115.429338 \nL 345.992956 115.272895 \nL 346.01198 115.447116 \nL 346.031004 115.230229 \nL 346.107099 115.312006 \nL 346.183195 115.194674 \nL 346.221243 115.219562 \nL 346.544649 115.336895 \nL 346.563673 115.219562 \nL 346.582697 115.472004 \nL 346.677817 115.450671 \nL 346.696841 115.173341 \nL 346.715865 115.454227 \nL 346.79196 115.297784 \nL 346.810984 115.47556 \nL 346.868056 115.208896 \nL 346.906104 115.415116 \nL 346.963176 115.194674 \nL 346.944152 115.472004 \nL 347.001223 115.251562 \nL 347.115367 115.44356 \nL 347.134391 115.198229 \nL 347.22951 115.276451 \nL 347.248534 115.461338 \nL 347.343654 115.376005 \nL 347.362678 115.283562 \nL 347.41975 115.397338 \nL 347.438773 115.319117 \nL 347.495845 115.244451 \nL 347.514869 115.400894 \nL 347.533893 115.230229 \nL 347.590965 115.411561 \nL 347.609989 115.294228 \nL 347.686084 115.440005 \nL 347.66706 115.223118 \nL 347.724132 115.361783 \nL 347.819252 115.411561 \nL 347.838276 115.30845 \nL 347.933395 115.447116 \nL 347.952419 115.344006 \nL 348.028515 115.223118 \nL 347.990467 115.429338 \nL 348.066563 115.283562 \nL 348.256802 115.365339 \nL 348.370945 115.255118 \nL 348.428017 115.34045 \nL 348.485089 115.319117 \nL 348.542161 115.173341 \nL 348.523137 115.468449 \nL 348.599232 115.208896 \nL 348.656304 115.418672 \nL 348.713376 115.287117 \nL 348.751424 115.397338 \nL 348.770448 115.265784 \nL 348.789472 115.44356 \nL 348.808495 115.216007 \nL 348.884591 115.354672 \nL 348.941663 115.208896 \nL 348.960687 115.415116 \nL 348.979711 115.240896 \nL 348.998735 115.429338 \nL 349.093854 115.411561 \nL 349.188974 115.319117 \nL 349.207998 115.415116 \nL 349.227022 115.440005 \nL 349.246046 115.336895 \nL 349.265069 115.390227 \nL 349.341165 115.283562 \nL 349.360189 115.418672 \nL 349.398237 115.301339 \nL 349.531404 115.379561 \nL 349.645548 115.26934 \nL 349.588476 115.415116 \nL 349.664572 115.294228 \nL 349.721643 115.432894 \nL 349.702619 115.258673 \nL 349.778715 115.386672 \nL 349.835787 115.255118 \nL 349.911883 115.329784 \nL 350.04505 115.159119 \nL 350.064074 115.468449 \nL 350.159193 115.333339 \nL 350.197241 115.386672 \nL 350.216265 115.262229 \nL 350.235289 115.44356 \nL 350.330409 115.322673 \nL 350.425528 115.383116 \nL 350.539672 115.23734 \nL 350.596744 115.422227 \nL 350.57772 115.219562 \nL 350.634791 115.358228 \nL 350.710887 115.201785 \nL 350.825031 115.564448 \nL 350.844054 115.276451 \nL 350.939174 115.322673 \nL 350.977222 115.198229 \nL 350.996246 115.504004 \nL 351.091365 115.511115 \nL 351.110389 115.137785 \nL 351.129413 115.54667 \nL 351.148437 115.048897 \nL 351.224533 115.461338 \nL 351.281605 115.16623 \nL 351.262581 115.468449 \nL 351.338676 115.344006 \nL 351.395748 115.454227 \nL 351.414772 115.244451 \nL 351.471844 115.40445 \nL 351.509892 115.301339 \nL 351.528915 115.511115 \nL 351.547939 115.248007 \nL 351.643059 115.312006 \nL 351.700131 115.500449 \nL 351.681107 115.244451 \nL 351.757202 115.379561 \nL 351.852322 115.194674 \nL 351.79525 115.390227 \nL 351.89037 115.233785 \nL 352.004513 115.454227 \nL 352.023537 115.191118 \nL 352.118657 115.365339 \nL 352.175729 115.408005 \nL 352.156705 115.272895 \nL 352.2328 115.347561 \nL 352.270848 115.287117 \nL 352.308896 115.333339 \nL 352.32792 115.159119 \nL 352.404016 115.376005 \nL 352.42304 115.255118 \nL 352.442063 115.240896 \nL 352.461087 115.347561 \nL 352.499135 115.319117 \nL 352.518159 115.440005 \nL 352.575231 115.255118 \nL 352.613279 115.351117 \nL 352.689374 115.447116 \nL 352.746446 115.198229 \nL 352.727422 115.518226 \nL 352.803518 115.297784 \nL 352.879614 115.26934 \nL 352.898637 115.400894 \nL 352.974733 115.283562 \nL 353.012781 115.379561 \nL 353.031805 115.280006 \nL 353.069853 115.425783 \nL 353.107901 115.383116 \nL 353.126924 115.379561 \nL 353.145948 115.162674 \nL 353.164972 115.47556 \nL 353.241068 115.333339 \nL 353.317164 115.223118 \nL 353.336187 115.532448 \nL 353.355211 115.162674 \nL 353.450331 115.244451 \nL 353.507403 115.450671 \nL 353.545451 115.397338 \nL 353.564474 115.176896 \nL 353.64057 115.290673 \nL 353.716666 115.468449 \nL 353.73569 115.244451 \nL 353.754714 115.429338 \nL 353.830809 115.173341 \nL 353.849833 115.454227 \nL 353.868857 115.290673 \nL 353.887881 115.23734 \nL 353.906905 115.383116 \nL 353.963977 115.315561 \nL 353.983001 115.411561 \nL 354.059096 115.226673 \nL 354.07812 115.368894 \nL 354.097144 115.208896 \nL 354.192264 115.336895 \nL 354.230312 115.354672 \nL 354.306407 115.184007 \nL 354.420551 115.468449 \nL 354.439575 115.240896 \nL 354.534694 115.287117 \nL 354.591766 115.447116 \nL 354.572742 115.230229 \nL 354.629814 115.393783 \nL 354.705909 115.141341 \nL 354.686886 115.568003 \nL 354.743957 115.255118 \nL 354.858101 115.518226 \nL 354.877125 115.120008 \nL 354.896149 115.653336 \nL 354.972244 115.347561 \nL 355.029316 115.429338 \nL 355.010292 115.272895 \nL 355.067364 115.418672 \nL 355.200531 115.212451 \nL 355.276627 115.514671 \nL 355.314675 115.408005 \nL 355.371747 115.283562 \nL 355.428818 115.319117 \nL 355.48589 115.432894 \nL 355.466866 115.173341 \nL 355.523938 115.361783 \nL 355.638081 115.137785 \nL 355.676129 115.080897 \nL 355.752225 115.500449 \nL 355.771249 115.219562 \nL 355.866368 115.415116 \nL 355.942464 115.120008 \nL 355.961488 115.575114 \nL 355.980512 115.141341 \nL 356.01856 115.493338 \nL 356.094655 115.287117 \nL 356.113679 115.255118 \nL 356.132703 115.34045 \nL 356.170751 115.354672 \nL 356.284895 115.315561 \nL 356.303918 115.223118 \nL 356.322942 115.351117 \nL 356.36099 115.333339 \nL 356.399038 115.297784 \nL 356.437086 115.44356 \nL 356.532205 115.582226 \nL 356.551229 115.034675 \nL 356.627325 115.64978 \nL 356.665373 115.432894 \nL 356.684397 115.461338 \nL 356.722445 115.553781 \nL 356.79854 115.073786 \nL 356.817564 115.635558 \nL 356.912684 115.500449 \nL 356.931708 115.105786 \nL 357.026827 115.26934 \nL 357.083899 115.479115 \nL 357.140971 115.351117 \nL 357.217066 115.422227 \nL 357.255114 115.564448 \nL 357.33121 115.219562 \nL 357.388282 115.429338 \nL 357.369258 115.20534 \nL 357.445353 115.233785 \nL 357.483401 115.30845 \nL 357.502425 115.127119 \nL 357.521449 115.454227 \nL 357.597545 115.216007 \nL 357.616569 115.457782 \nL 357.711688 115.315561 \nL 357.806808 115.400894 \nL 357.749736 115.255118 \nL 357.825832 115.319117 \nL 357.920951 115.219562 \nL 357.939975 115.422227 \nL 358.035095 115.344006 \nL 358.054119 115.223118 \nL 358.130214 115.301339 \nL 358.30143 115.440005 \nL 358.377525 115.262229 \nL 358.396549 115.511115 \nL 358.415573 115.351117 \nL 358.434597 115.479115 \nL 358.510693 115.432894 \nL 358.586788 114.817789 \nL 358.567764 115.720891 \nL 358.64386 115.020453 \nL 358.662884 115.859556 \nL 358.681908 114.789344 \nL 358.758004 115.728002 \nL 358.777028 115.077342 \nL 358.872147 115.361783 \nL 358.929219 115.706669 \nL 358.910195 114.956454 \nL 358.948243 115.095119 \nL 358.986291 115.600003 \nL 359.005315 115.034675 \nL 359.08141 115.525337 \nL 359.100434 115.255118 \nL 359.195554 115.304895 \nL 359.233602 115.422227 \nL 359.271649 115.109341 \nL 359.290673 115.592892 \nL 359.385793 115.361783 \nL 359.404817 115.056008 \nL 359.442865 115.379561 \nL 359.499936 115.187563 \nL 359.51896 115.50756 \nL 359.537984 115.052453 \nL 359.61408 115.312006 \nL 359.652128 115.450671 \nL 359.671152 115.144896 \nL 359.766271 115.564448 \nL 359.747247 114.988454 \nL 359.785295 115.376005 \nL 359.823343 115.71378 \nL 359.899439 114.935121 \nL 359.975534 115.600003 \nL 360.013582 115.44356 \nL 360.05163 115.159119 \nL 360.089678 115.251562 \nL 360.14675 115.660447 \nL 360.127726 115.027564 \nL 360.203821 115.624892 \nL 360.222845 114.903121 \nL 360.241869 115.884445 \nL 360.317965 115.155563 \nL 360.336989 115.568003 \nL 360.413084 115.486226 \nL 360.432108 115.080897 \nL 360.508204 115.624892 \nL 360.527228 115.351117 \nL 360.546252 115.201785 \nL 360.565276 115.703113 \nL 360.603324 115.301339 \nL 360.660395 115.61067 \nL 360.641371 115.10223 \nL 360.717467 115.447116 \nL 360.736491 115.226673 \nL 360.831611 115.358228 \nL 360.907706 115.233785 \nL 360.983802 115.504004 \nL 361.02185 115.436449 \nL 361.059898 115.496893 \nL 361.135993 115.013342 \nL 361.155017 115.553781 \nL 361.250137 115.550226 \nL 361.269161 115.034675 \nL 361.36428 115.077342 \nL 361.4594 115.041786 \nL 361.478424 115.852445 \nL 361.573543 115.863112 \nL 361.592567 114.856899 \nL 361.668663 115.923556 \nL 361.649639 114.810678 \nL 361.706711 115.23734 \nL 361.763782 115.511115 \nL 361.744758 115.070231 \nL 361.80183 115.393783 \nL 361.858902 115.006231 \nL 361.839878 115.699558 \nL 361.915974 115.30845 \nL 361.992069 115.080897 \nL 362.011093 116.101332 \nL 362.030117 114.540458 \nL 362.125237 115.287117 \nL 362.163285 115.26934 \nL 362.182309 115.688891 \nL 362.23938 114.856899 \nL 362.258404 116.044443 \nL 362.296452 115.322673 \nL 362.3345 114.917343 \nL 362.353524 116.222219 \nL 362.372548 114.423126 \nL 362.467667 115.06312 \nL 362.505715 115.731557 \nL 362.524739 115.304895 \nL 362.581811 114.128018 \nL 362.562787 116.442662 \nL 362.638883 114.18135 \nL 362.657906 116.485328 \nL 362.753026 115.322673 \nL 362.791074 114.938676 \nL 362.86717 115.788446 \nL 362.924241 114.714678 \nL 362.905217 116.005332 \nL 362.981313 115.301339 \nL 363.038385 115.948444 \nL 363.019361 114.704012 \nL 363.076433 115.468449 \nL 363.133504 114.817789 \nL 363.11448 115.639114 \nL 363.190576 115.038231 \nL 363.2096 115.923556 \nL 363.228624 114.504903 \nL 363.30472 115.400894 \nL 363.361791 115.493338 \nL 363.399839 114.963565 \nL 363.418863 115.731557 \nL 363.513983 115.301339 \nL 363.533007 115.248007 \nL 363.552031 115.315561 \nL 363.590078 114.7609 \nL 363.628126 115.824001 \nL 363.64715 114.693345 \nL 363.74227 115.155563 \nL 363.799341 115.916444 \nL 363.818365 114.821344 \nL 363.856413 115.582226 \nL 363.875437 115.020453 \nL 363.894461 115.653336 \nL 363.970557 115.155563 \nL 364.008605 115.589337 \nL 364.0847 114.519125 \nL 364.103724 116.097776 \nL 364.122748 114.892455 \nL 364.160796 116.478217 \nL 364.17982 113.765354 \nL 364.274939 114.590235 \nL 364.408107 115.856001 \nL 364.427131 114.7929 \nL 364.427131 114.7929 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 44.845313 224.64 \nL 44.845313 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 379.645313 224.64 \nL 379.645313 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 44.845313 224.64 \nL 379.645313 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 44.845313 7.2 \nL 379.645313 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p0bbf68628e\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"44.845313\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "waveform, sample_rate, utterance, speaker_id, utterance_id = test_dataset[0]\n",
    "\n",
    "print(\"Shape of waveform: {}\".format(waveform.size()))\n",
    "print(\"Sample rate of waveform: {}\".format(sample_rate))\n",
    "\n",
    "plt.plot(waveform.t().numpy());\n",
    "\n",
    "ipd.Audio(waveform.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation - SpecAugment\n",
    "\n",
    "Data augmentation is a technique used to artificially increase the diversity of your dataset in order to increase your dataset size. This strategy is especially helpful when data is scarce or if your model is overfitting. For speech recognition, you can do the standard augmentation techniques, like changing the pitch, speed, injecting noise, and adding reverb to your audio data.\n",
    "\n",
    "We found Spectrogram Augmentation (SpecAugment), to be a much simpler and more effective approach. SpecAugment, was first introduced in the paper SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition (https://arxiv.org/abs/1904.08779), in which the authors found that simply cutting out random blocks of consecutive time and frequency dimensions improved the models generalization abilities significantly!\n",
    "\n",
    "<img src=\"img/transformer_freq.png\" title=\"frequency\" style=\"width: 480px;\" />\n",
    "\n",
    "In PyTorch, you can use the torchaudio function FrequencyMasking to mask out the frequency dimension, and TimeMasking for the time dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchaudio/functional/functional.py:358: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n  \"At least one mel filterbank has all zero values. \"\n"
     ]
    }
   ],
   "source": [
    "train_audio_transforms = nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data, we'll need to transform the audio into Mel Spectrograms, and map the character labels for each audio sample into integer labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextTransform:\n",
    "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
    "    def __init__(self):\n",
    "        char_map_str = \"\"\"\n",
    "        ' 0\n",
    "        <SPACE> 1\n",
    "        a 2\n",
    "        b 3\n",
    "        c 4\n",
    "        d 5\n",
    "        e 6\n",
    "        f 7\n",
    "        g 8\n",
    "        h 9\n",
    "        i 10\n",
    "        j 11\n",
    "        k 12\n",
    "        l 13\n",
    "        m 14\n",
    "        n 15\n",
    "        o 16\n",
    "        p 17\n",
    "        q 18\n",
    "        r 19\n",
    "        s 20\n",
    "        t 21\n",
    "        u 22\n",
    "        v 23\n",
    "        w 24\n",
    "        x 25\n",
    "        y 26\n",
    "        z 27\n",
    "        \"\"\"\n",
    "        self.char_map = {}\n",
    "        self.index_map = {}\n",
    "        for line in char_map_str.strip().split('\\n'):\n",
    "            ch, index = line.split()\n",
    "            self.char_map[ch] = int(index)\n",
    "            self.index_map[int(index)] = ch\n",
    "        self.index_map[1] = ' '\n",
    "\n",
    "    def text_to_int(self, text):\n",
    "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
    "        int_sequence = []\n",
    "        for c in text:\n",
    "            if c == ' ':\n",
    "                ch = self.char_map['<SPACE>']\n",
    "            else:\n",
    "                ch = self.char_map[c]\n",
    "            int_sequence.append(ch)\n",
    "        return int_sequence\n",
    "\n",
    "    def int_to_text(self, labels):\n",
    "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
    "        string = []\n",
    "        for i in labels:\n",
    "            string.append(self.index_map[i])\n",
    "        return ''.join(string).replace('<SPACE>', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
    "\n",
    "text_transform = TextTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(data, data_type=\"train\"):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    for (waveform, _, utterance, _, _) in data:\n",
    "        if data_type == 'train':\n",
    "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        else:\n",
    "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        spectrograms.append(spec)\n",
    "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
    "        labels.append(label)\n",
    "        input_lengths.append(spec.shape[0]//2)\n",
    "        label_lengths.append(len(label))\n",
    "\n",
    "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model - Deep Speech 2\n",
    "\n",
    "The model will be similar to the Deep Speech 2 architecture. The model will have two main neural network modules - N layers of Residual Convolutional Neural Networks (ResCNN) to learn the relevant audio features, and a set of Bidirectional Recurrent Neural Networks (BiRNN) to leverage the learned ResCNN audio features. The model is topped off with a fully connected layer used to classify characters per time step.\n",
    "\n",
    "<img src=\"img/transformer_deepspeech2.png\" title=\"deepspeech2\" style=\"width: 800px;\" />\n",
    "\n",
    "Convolutional Neural Networks (CNN) are great at extracting abstract features, and we'll apply the same feature extraction power to audio spectrograms. Instead of just vanilla CNN layers, we choose to use Residual CNN layers. Residual connections (AKA skip connections) were first introduced in the paper Deep Residual Learning for Image Recognition, where the author found that you can build really deep networks with good accuracy gains if you add these connections to your CNN's. Adding these Residual connections also helps the model learn faster and generalize better. The paper Visualizing the Loss Landscape of Neural Nets shows that networks with residual connections have a “flatter” loss surface, making it easier for models to navigate the loss landscape and find a lower and more generalizable minima.\n",
    "\n",
    "<img src=\"img/transformer_skipconncompare.png\" title=\"\" style=\"width: 400px;\" />\n",
    "\n",
    "Recurrent Neural Networks (RNN) are naturally great at sequence modeling problems. RNN's processes the audio features step by step, making a prediction for each frame while using context from previous frames. We use BiRNN's because we want the context of not only the frame before each step, but the frames after it as well. This can help the model make better predictions, as each frame in the audio will have more information before making a prediction. We use Gated Recurrent Unit (GRU's) variant of RNN's as it needs less computational resources than LSTM's, and works just as well in some cases.\n",
    "\n",
    "The model outputs a probability matrix for characters which we'll use to feed into our decoder to extract what the model believes are the highest probability characters that were spoken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
    "        except with layer norm instead of batch norm\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        return x # (batch, channel, feature, time)\n",
    "\n",
    "class BidirectionalGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "\n",
    "        self.BiGRU = nn.GRU(\n",
    "            input_size=rnn_dim, hidden_size=hidden_size,\n",
    "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = F.gelu(x)\n",
    "        x, _ = self.BiGRU(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SpeechRecognitionModel(nn.Module):\n",
    "    \"\"\"Speech Recognition Model Inspired by DeepSpeech 2\"\"\"\n",
    "\n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(SpeechRecognitionModel, self).__init__()\n",
    "        n_feats = n_feats//2\n",
    "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.rescnn_layers = nn.Sequential(*[\n",
    "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
    "            for _ in range(n_cnn_layers)\n",
    "        ])\n",
    "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
    "        self.birnn_layers = nn.Sequential(*[\n",
    "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
    "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
    "            for i in range(n_rnn_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(rnn_dim, n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.rescnn_layers(x)\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        x = x.transpose(1, 2) # (batch, time, feature)\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.birnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics\n",
    "\n",
    "Here are implementations of the common evaluation metrics for speech recognition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_wer(wer_scores, combined_ref_len):\n",
    "    return float(sum(wer_scores)) / float(combined_ref_len)\n",
    "\n",
    "\n",
    "def _levenshtein_distance(ref, hyp):\n",
    "    \"\"\"Levenshtein distance is a string metric for measuring the difference\n",
    "    between two sequences. Informally, the levenshtein disctance is defined as\n",
    "    the minimum number of single-character edits (substitutions, insertions or\n",
    "    deletions) required to change one word into the other. We can naturally\n",
    "    extend the edits to word level when calculate levenshtein disctance for\n",
    "    two sentences.\n",
    "    \"\"\"\n",
    "    m = len(ref)\n",
    "    n = len(hyp)\n",
    "\n",
    "    # special case\n",
    "    if ref == hyp:\n",
    "        return 0\n",
    "    if m == 0:\n",
    "        return n\n",
    "    if n == 0:\n",
    "        return m\n",
    "\n",
    "    if m < n:\n",
    "        ref, hyp = hyp, ref\n",
    "        m, n = n, m\n",
    "\n",
    "    # use O(min(m, n)) space\n",
    "    distance = np.zeros((2, n + 1), dtype=np.int32)\n",
    "\n",
    "    # initialize distance matrix\n",
    "    for j in range(0,n + 1):\n",
    "        distance[0][j] = j\n",
    "\n",
    "    # calculate levenshtein distance\n",
    "    for i in range(1, m + 1):\n",
    "        prev_row_idx = (i - 1) % 2\n",
    "        cur_row_idx = i % 2\n",
    "        distance[cur_row_idx][0] = i\n",
    "        for j in range(1, n + 1):\n",
    "            if ref[i - 1] == hyp[j - 1]:\n",
    "                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n",
    "            else:\n",
    "                s_num = distance[prev_row_idx][j - 1] + 1\n",
    "                i_num = distance[cur_row_idx][j - 1] + 1\n",
    "                d_num = distance[prev_row_idx][j] + 1\n",
    "                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n",
    "\n",
    "    return distance[m % 2][n]\n",
    "\n",
    "\n",
    "def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
    "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
    "    hypothesis sequence in word-level.\n",
    "    :param reference: The reference sentence.\n",
    "    :type reference: basestring\n",
    "    :param hypothesis: The hypothesis sentence.\n",
    "    :type hypothesis: basestring\n",
    "    :param ignore_case: Whether case-sensitive or not.\n",
    "    :type ignore_case: bool\n",
    "    :param delimiter: Delimiter of input sentences.\n",
    "    :type delimiter: char\n",
    "    :return: Levenshtein distance and word number of reference sentence.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    if ignore_case == True:\n",
    "        reference = reference.lower()\n",
    "        hypothesis = hypothesis.lower()\n",
    "\n",
    "    ref_words = reference.split(delimiter)\n",
    "    hyp_words = hypothesis.split(delimiter)\n",
    "\n",
    "    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n",
    "    return float(edit_distance), len(ref_words)\n",
    "\n",
    "\n",
    "def char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n",
    "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
    "    hypothesis sequence in char-level.\n",
    "    :param reference: The reference sentence.\n",
    "    :type reference: basestring\n",
    "    :param hypothesis: The hypothesis sentence.\n",
    "    :type hypothesis: basestring\n",
    "    :param ignore_case: Whether case-sensitive or not.\n",
    "    :type ignore_case: bool\n",
    "    :param remove_space: Whether remove internal space characters\n",
    "    :type remove_space: bool\n",
    "    :return: Levenshtein distance and length of reference sentence.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    if ignore_case == True:\n",
    "        reference = reference.lower()\n",
    "        hypothesis = hypothesis.lower()\n",
    "\n",
    "    join_char = ' '\n",
    "    if remove_space == True:\n",
    "        join_char = ''\n",
    "\n",
    "    reference = join_char.join(filter(None, reference.split(' ')))\n",
    "    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
    "\n",
    "    edit_distance = _levenshtein_distance(reference, hypothesis)\n",
    "    return float(edit_distance), len(reference)\n",
    "\n",
    "\n",
    "def wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
    "    \"\"\"Calculate word error rate (WER). WER compares reference text and\n",
    "    hypothesis text in word-level. WER is defined as:\n",
    "    .. math::\n",
    "        WER = (Sw + Dw + Iw) / Nw\n",
    "    where\n",
    "    .. code-block:: text\n",
    "        Sw is the number of words subsituted,\n",
    "        Dw is the number of words deleted,\n",
    "        Iw is the number of words inserted,\n",
    "        Nw is the number of words in the reference\n",
    "    We can use levenshtein distance to calculate WER. Please draw an attention\n",
    "    that empty items will be removed when splitting sentences by delimiter.\n",
    "    :param reference: The reference sentence.\n",
    "    :type reference: basestring\n",
    "    :param hypothesis: The hypothesis sentence.\n",
    "    :type hypothesis: basestring\n",
    "    :param ignore_case: Whether case-sensitive or not.\n",
    "    :type ignore_case: bool\n",
    "    :param delimiter: Delimiter of input sentences.\n",
    "    :type delimiter: char\n",
    "    :return: Word error rate.\n",
    "    :rtype: float\n",
    "    :raises ValueError: If word number of reference is zero.\n",
    "    \"\"\"\n",
    "    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n",
    "                                         delimiter)\n",
    "\n",
    "    if ref_len == 0:\n",
    "        raise ValueError(\"Reference's word number should be greater than 0.\")\n",
    "\n",
    "    wer = float(edit_distance) / ref_len\n",
    "    return wer\n",
    "\n",
    "\n",
    "def cer(reference, hypothesis, ignore_case=False, remove_space=False):\n",
    "    \"\"\"Calculate charactor error rate (CER). CER compares reference text and\n",
    "    hypothesis text in char-level. CER is defined as:\n",
    "    .. math::\n",
    "        CER = (Sc + Dc + Ic) / Nc\n",
    "    where\n",
    "    .. code-block:: text\n",
    "        Sc is the number of characters substituted,\n",
    "        Dc is the number of characters deleted,\n",
    "        Ic is the number of characters inserted\n",
    "        Nc is the number of characters in the reference\n",
    "    We can use levenshtein distance to calculate CER. Chinese input should be\n",
    "    encoded to unicode. Please draw an attention that the leading and tailing\n",
    "    space characters will be truncated and multiple consecutive space\n",
    "    characters in a sentence will be replaced by one space character.\n",
    "    :param reference: The reference sentence.\n",
    "    :type reference: basestring\n",
    "    :param hypothesis: The hypothesis sentence.\n",
    "    :type hypothesis: basestring\n",
    "    :param ignore_case: Whether case-sensitive or not.\n",
    "    :type ignore_case: bool\n",
    "    :param remove_space: Whether remove internal space characters\n",
    "    :type remove_space: bool\n",
    "    :return: Character error rate.\n",
    "    :rtype: float\n",
    "    :raises ValueError: If the reference length is zero.\n",
    "    \"\"\"\n",
    "    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n",
    "                                         remove_space)\n",
    "\n",
    "    if ref_len == 0:\n",
    "        raise ValueError(\"Length of reference should be greater than 0.\")\n",
    "\n",
    "    cer = float(edit_distance) / ref_len\n",
    "    return cer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring experiments using comet.ml\n",
    "\n",
    "Comet.ml provides a platform that allows deep learning researchers to track, compare, explain, and optimize their experiments and models. Comet.ml has improved our productivity at AssemblyAI and we highly recommend using this platform for teams doing any sort of data science experiments. Comet.ml is super easy to set up. And works with just a few lines of code.\n",
    "\n",
    "<img src=\"img/transformer_comet_ml.png\" title=\"comet_ml\" style=\"width: 800px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/kagakuosakura/rtml-class/e9ffac64f84a4ca3adba434eee0bf792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To use comet.ml, which is kind of cool but requires an account and API key from them,\n",
    "# go to comet.ml, create an account, create project, and create an API key. Then fill\n",
    "# in the variables\n",
    "\n",
    "# Create an experiment with your api key\n",
    "experiment = Experiment(\n",
    "    api_key=\"9neHTMUQ1vfL6kScdIX9UTg4n\",\n",
    "    project_name=\"rtml-class\",\n",
    "    workspace=\"kagakuosakura\",\n",
    ")\n",
    "# Later, you can track metrics in the cloud GUI. To log a loss:\n",
    "\n",
    "# experiment.log_metric('loss', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterMeter(object):\n",
    "    \"\"\"keeps track of total iterations\"\"\"\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.val += 1\n",
    "\n",
    "    def get(self):\n",
    "        return self.val\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, experiment):\n",
    "    model.train()\n",
    "    data_len = len(train_loader.dataset)\n",
    "    with experiment.train():\n",
    "        for batch_idx, _data in enumerate(train_loader):\n",
    "            spectrograms, labels, input_lengths, label_lengths = _data \n",
    "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(spectrograms)  # (batch, time, n_class)\n",
    "            output = F.log_softmax(output, dim=2)\n",
    "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "            loss.backward()\n",
    "\n",
    "            experiment.log_metric('loss', loss.item(), step=iter_meter.get())\n",
    "            experiment.log_metric('learning_rate', scheduler.get_lr(), step=iter_meter.get())\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            iter_meter.step()\n",
    "            if batch_idx % 100 == 0 or batch_idx == data_len:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(spectrograms), data_len,\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, criterion, epoch, iter_meter, experiment):\n",
    "    print('\\nevaluating...')\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_cer, test_wer = [], []\n",
    "    with experiment.test():\n",
    "        with torch.no_grad():\n",
    "            for i, _data in enumerate(test_loader):\n",
    "                spectrograms, labels, input_lengths, label_lengths = _data \n",
    "                spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "                output = model(spectrograms)  # (batch, time, n_class)\n",
    "                output = F.log_softmax(output, dim=2)\n",
    "                output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "                loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "                test_loss += loss.item() / len(test_loader)\n",
    "\n",
    "                decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "                for j in range(len(decoded_preds)):\n",
    "                    test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
    "                    test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
    "\n",
    "\n",
    "    avg_cer = sum(test_cer)/len(test_cer)\n",
    "    avg_wer = sum(test_wer)/len(test_wer)\n",
    "    experiment.log_metric('test_loss', test_loss, step=iter_meter.get())\n",
    "    experiment.log_metric('cer', avg_cer, step=iter_meter.get())\n",
    "    experiment.log_metric('wer', avg_wer, step=iter_meter.get())\n",
    "\n",
    "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking the Right Optimizer and Scheduler - AdamW with Super Convergence\n",
    "\n",
    "AdamW was first introduced in Decoupled Weight Decay Regularization (https://arxiv.org/abs/1711.05101), and is considered a “fix” to Adam. The paper pointed out that the original Adam algorithm has a wrong implementation of weight decay, which AdamW attempts to fix. This fix helps with Adam's generalization problem.\n",
    "\n",
    "<img src=\"img/transformer_adamw.jpeg\" title=\"AdamW\" style=\"width: 400px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CTC Loss Function - Aligning Audio to Transcript\n",
    "\n",
    "The innovation of the CTC loss function is that it allows us to skip this step. Our model will learn to align the transcript itself during training. The key to this is the “blank” label introduced by CTC, which gives the model the ability to say that a certain audio frame did not produce a character.\n",
    "\n",
    "<img src=\"img/transformer_ctcloss.png\" title=\"ctc loss\" style=\"width: 400px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SpeechRecognitionModel(\n  (cnn): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n  (rescnn_layers): Sequential(\n    (0): ResidualCNN(\n      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n      (layer_norm1): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n      (layer_norm2): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (1): ResidualCNN(\n      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n      (layer_norm1): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n      (layer_norm2): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (2): ResidualCNN(\n      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n      (layer_norm1): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n      (layer_norm2): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)\n  (birnn_layers): Sequential(\n    (0): BidirectionalGRU(\n      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (1): BidirectionalGRU(\n      (BiGRU): GRU(1024, 512, bidirectional=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (2): BidirectionalGRU(\n      (BiGRU): GRU(1024, 512, bidirectional=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (3): BidirectionalGRU(\n      (BiGRU): GRU(1024, 512, bidirectional=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (4): BidirectionalGRU(\n      (BiGRU): GRU(1024, 512, bidirectional=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=1024, out_features=512, bias=True)\n    (1): GELU()\n    (2): Dropout(p=0.1, inplace=False)\n    (3): Linear(in_features=512, out_features=29, bias=True)\n  )\n)\nNum Model Parameters 23705373\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-32f62af90873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCTCLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n\u001b[0;32m---> 48\u001b[0;31m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                                         anneal_strategy='linear')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "learning_rate=5e-4\n",
    "batch_size=20\n",
    "epochs=10\n",
    "\n",
    "# experiment=Experiment(api_key='dummy_key', disabled=True)\n",
    "\n",
    "hparams = {\n",
    "        \"n_cnn_layers\": 3,\n",
    "        \"n_rnn_layers\": 5,\n",
    "        \"rnn_dim\": 512,\n",
    "        \"n_class\": 29,\n",
    "        \"n_feats\": 128,\n",
    "        \"stride\":2,\n",
    "        \"dropout\": 0.1,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs\n",
    "    }\n",
    "\n",
    "# experiment.log_parameters(hparams)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "# train_loader = data.DataLoader(dataset=train_dataset,\n",
    "#                             batch_size=hparams['batch_size'],\n",
    "#                             shuffle=True,\n",
    "#                             collate_fn=lambda x: data_processing(x, 'train'),\n",
    "#                             **kwargs)\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                            batch_size=hparams['batch_size'],\n",
    "                            shuffle=False,\n",
    "                            collate_fn=lambda x: data_processing(x, 'valid'),\n",
    "                            **kwargs)\n",
    "\n",
    "model = SpeechRecognitionModel(\n",
    "    hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
    "    hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
    "    ).to(device)\n",
    "\n",
    "print(model)\n",
    "print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
    "criterion = nn.CTCLoss(blank=28).to(device)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
    "                                        steps_per_epoch=int(len(train_loader)),\n",
    "                                        epochs=hparams['epochs'],\n",
    "                                        anneal_strategy='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Your Speech Model\n",
    "When Evaluating your speech recognition model, the industry standard is using the Word Error Rate (WER) as the metric. The Word Error Rate does exactly what it says - it takes the transcription your model outputs, and the true transcription, and measures the error between them. You can see how that's implemented here. Another useful metric is called the Character Error Rate (CER). The CER measures the error of the characters between the model's output and the true labels. These metrics are helpful to measure how well your model performs.\n",
    "\n",
    "For this tutorial, we'll use a \"greedy\" decoding method to process our model's output into characters that can be combined to create the transcript. A \"greedy\" decoder takes in the model output, which is a softmax probability matrix of characters, and for each time step (spectrogram frame), it chooses the label with the highest probability. If the label is a blank label, we remove it from the final transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
    "    arg_maxes = torch.argmax(output, dim=2)\n",
    "    decodes = []\n",
    "    targets = []\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "        decode = []\n",
    "        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j != 0 and index == args[j -1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "        decodes.append(text_transform.int_to_text(decode))\n",
    "    return decodes, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training and evaluating on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iter_meter = IterMeter()\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#     train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter, experiment)\n",
    "#     print('saving...')\n",
    "#     torch.save(model.state_dict(), f'./model/SpeechRecognitionModel_{epoch}.weight')\n",
    "#     print('save complete')\n",
    "#     test(model, device, test_loader, criterion, epoch, iter_meter, experiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 2.6771, Average CER: 0.645727 Average WER: 1.1629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./models/SpeechRecognitionModel_2.weight'))\n",
    "test(model, device, test_loader, criterion, 0, iter_meter, experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-lab exercises\n",
    "\n",
    "1. Spend some time to understand the Transformer and Speech Recognition examples.\n",
    "2. After training, test the two models on some data (text, audio) you provide yourself\n",
    "\n",
    "## Homework\n",
    "\n",
    "Since you're all extremely busy with your projects (RIGHT??), for the homework for this week,\n",
    "write an explanation of the steps that would be needed to adapt the PyTorch transformer to\n",
    "the speech recognition task. Be specific in how you would do the implementation, but you do\n",
    "not need to ac"
   ]
  },
  {
   "source": [
    "## Implement transformer to speech recognition model\n",
    "\n",
    "We can add transformer layer before BiRNN layer of speech recognition model. This will encourage impotant audio features which come from ResCNN."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}