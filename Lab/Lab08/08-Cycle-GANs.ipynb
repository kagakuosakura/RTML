{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN\n",
    "\n",
    "CycleGAN is a very popular GAN architecture. It is used to learn transformation between images of different styles.\n",
    "\n",
    "The examples of CycleGAN:\n",
    "\n",
    " - a map between artistic and realistic images,\n",
    " - a transformation between images of horse and zebra,\n",
    " - a transformation between winter image and summer image\n",
    " - FaceApp or DeepFake\n",
    "\n",
    "Assume that X is a set of images of horse and Y is a set of images of zebra.\n",
    "\n",
    "The goal of CycleGAN is to learn a mapping function G: X-> Y such that images generated by G(X) are indistinguishable from the image of Y. This objective is achieved using an Adversarial loss. This formulation not only learns G, but it also learns an inverse mapping function F: Y->X and use cycle-consistency loss to enforce **F(G(X)) = X**.\n",
    "\n",
    "While training, 2 kinds of training observations are given as input.\n",
    "\n",
    " - One set of observations have paired images {Xi, Yi} for i where each Xi has it’s Yi counterpart.\n",
    " - The other set of observations has a set of images from X and another set of images from Y without any match between Xi and Yi.\n",
    "\n",
    "As part of Adversarial formulation, there is one Discriminator Dx that classifies whether the transformed Y is indistinguishable from Y. Similarly, there is one more Discriminator Dy that classifies whether  is indistinguishable from X.\n",
    "\n",
    "<img src=\"img/CycleGANmodel.jpg\" title=\"CycleGAN\" style=\"width: 640px;\" />\n",
    "\n",
    "Generator\n",
    "\n",
    "<img src=\"img/CycleGANGenerator.jpg\" title=\"CycleGAN Generator\" style=\"width: 640px;\" />\n",
    "\n",
    "Discriminator\n",
    "\n",
    "<img src=\"img/CycleGANdiscriminator.jpg\" title=\"CycleGAN Discriminator\" style=\"width: 640px;\" />\n",
    "\n",
    "Along with Adversarial Loss, CycleGAN uses cycle-consistency loss to enable training without paired images and this additional loss help the model to minimize reconstruction loss F(G(x)) ≈ X and G(F(Y)) ≈ Y\n",
    "\n",
    "So, All-in-all CycleGAN formulation comprises of 3 individual loss:\n",
    "\n",
    "<img src=\"img/CycleGAN-formulation.png\" title=\"CycleGAN formulation\" style=\"width: 560px;\" />\n",
    "\n",
    "Optimization:\n",
    "\n",
    "<img src=\"img/Optimized-loss-function-CycleGan.png\" title=\"CycleGAN optimization\" style=\"width: 320px;\" />\n",
    "\n",
    "## Results\n",
    "\n",
    "<img src=\"img/CycleGANResultsA2B.jpg\" title=\"CycleGAN Results\" style=\"width: 640px;\" />\n",
    "\n",
    ".\n",
    "\n",
    "<img src=\"img/CycleGANdistortionB2A.jpg\" title=\"CycleGAN Distort\" style=\"width: 640px;\" />\n",
    "\n",
    "In the https://github.com/diegoalejogm/gans/blob/master/CycleGans.ipynb has an examples of CycleGAN from scratch. You can take a look\n",
    "\n",
    "## Get and prepare Cycle GAN implementation\n",
    "\n",
    "Download the Cycle GAN implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'pytorch-CycleGAN-and-pix2pix'...\n",
      "remote: Enumerating objects: 2337, done.\u001b[K\n",
      "remote: Total 2337 (delta 0), reused 0 (delta 0), pack-reused 2337\u001b[K\n",
      "Receiving objects: 100% (2337/2337), 8.09 MiB | 5.66 MiB/s, done.\n",
      "Resolving deltas: 100% (1499/1499), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this implementation, there are two libraries needs to be installed, dominate and visdom. It is used for monitoring the result of training via web server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting dominate\n",
      "  Downloading dominate-2.6.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting visdom\n",
      "  Downloading visdom-0.1.8.9.tar.gz (676 kB)\n",
      "\u001b[K     |████████████████████████████████| 676 kB 2.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.6/dist-packages (from visdom) (1.19.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom) (1.5.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom) (2.25.1)\n",
      "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom) (6.1)\n",
      "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom) (21.0.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from visdom) (1.11.0)\n",
      "Collecting jsonpatch\n",
      "  Downloading jsonpatch-1.31-py2.py3-none-any.whl (12 kB)\n",
      "Collecting torchfile\n",
      "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
      "Collecting websocket-client\n",
      "  Downloading websocket_client-0.58.0-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 984 kB/s \n",
      "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from visdom) (8.1.0)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Downloading jsonpointer-2.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/lib/python3/dist-packages (from requests->visdom) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->visdom) (2018.1.18)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->visdom) (1.22)\n",
      "Building wheels for collected packages: visdom, torchfile\n",
      "  Building wheel for visdom (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for visdom: filename=visdom-0.1.8.9-py3-none-any.whl size=668534 sha256=1077f80e56663fe997a666a4a58fed47a32b82264c0de6863c13ba58e1fc7394\n",
      "  Stored in directory: /root/.cache/pip/wheels/2d/cd/fb/005445070865d4e45365b2946ee88085a7392370f152cf371c\n",
      "  Building wheel for torchfile (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=6623 sha256=4dc120cdcdbb275f057454c73d8d01b079dbdf6309aaab071c15c90745089e69\n",
      "  Stored in directory: /root/.cache/pip/wheels/55/79/ec/084a3a2e348d72852cc0c13c559c923c13ca54db86e699b681\n",
      "Successfully built visdom torchfile\n",
      "Installing collected packages: jsonpointer, idna, websocket-client, torchfile, jsonpatch, visdom, dominate\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.1\n",
      "    Uninstalling idna-3.1:\n",
      "      Successfully uninstalled idna-3.1\n",
      "Successfully installed dominate-2.6.0 idna-2.10 jsonpatch-1.31 jsonpointer-2.0 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-0.58.0\n"
     ]
    }
   ],
   "source": [
    "!pip install dominate visdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, download a data set:\n",
    "\n",
    "(Try a different data set if you like.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/bin/bash: ./datasets/download_cyclegan_dataset.sh: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cd pytorch-CycleGAN-and-pix2pix\n",
    "!./datasets/download_cyclegan_dataset.sh horse2zebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a training run\n",
    "\n",
    "We won't be able to finish a training run in class -- 200 epochs of the horse2zebra dataset with batch size 1 takes about 22 hours on our GPUs. However, we can start a run and see how it goes.\n",
    "\n",
    "We'll also see an example of how to use visdom, which is probably better than matplotlib for visualization when we are running on the server:\n",
    "\n",
    "### In terminal 1:\n",
    "\n",
    "    python3 -m visdom.server\n",
    "   \n",
    "### In terminal 2 (ssh with parameter -L 8097:localhost:8097):\n",
    "\n",
    "    python3 train.py --dataroot ./datasets/horse2zebra --name horse2zebra_cyclegan --model cycle_gan\n",
    "    python3 train.py -u --dataroot ./datasets/ait2celeb --name ait2celeb_cyclegan --model cycle_gan > ../log_ait2celeb.log\n",
    "\n",
    "### Inference\n",
    "\n",
    "    python3 test.py --gpu_ids '2' --dataroot ./datasets/ait2celeb --name ait2celeb_cyclegan --model cycle_gan\n",
    "\n",
    "## Tips\n",
    "\n",
    "You can understand how to config dataset in CycleGAN.ipynb\n",
    "\n",
    "Configuration commands are in \\options folder\n",
    "\n",
    "You should see your GANs off and running. After every 100 iterations, you should get an update of the different losses and a visualization of results for a real pair (x, y), including G(x), F(y) (fakeB, fakeA), F(G(x), G(F(y)) (recA, recB), F(x), and G(y) (idtB, idtA). If we can all run concurrently you should be getting horsey zebras and somewhat striped horses by the end of lab.\n",
    "\n",
    "## My experiment result from the CycleGAN\n",
    "\n",
    "I had run modern houses and transform to Thai houses. This is one of the result which I tried to train it for 1 day.\n",
    "\n",
    "<img src=\"img/Modern2Thai.png\" title=\"modern2thai\" style=\"width: 640px;\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}