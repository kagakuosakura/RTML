{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading network.....\n",
      "Edit conv layer 114 (layer after SPP)\n",
      "Network successfully loaded\n",
      "['/root/Lab/Lab04/cocoimages/dog-cycle-car.png']\n",
      "dog-cycle-car.png    predicted in  0.016 seconds\n",
      "Objects Detected:    bicycle truck dog\n",
      "----------------------------------------------------------\n",
      "SUMMARY\n",
      "----------------------------------------------------------\n",
      "Task                     : Time Taken (in seconds)\n",
      "\n",
      "Reading addresses        : 0.001\n",
      "Loading batch            : 0.022\n",
      "Detection (1 images)     : 0.068\n",
      "Output Processing        : 0.000\n",
      "Drawing Boxes            : 0.031\n",
      "Average time_per_img     : 0.122\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import time\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import cv2 \n",
    "from util import *\n",
    "import argparse\n",
    "import os \n",
    "import os.path as osp\n",
    "from darknet import Darknet\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "images = \"cocoimages\"\n",
    "batch_size = 4\n",
    "confidence = 0.5\n",
    "nms_thesh = 0.4\n",
    "start = 0\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "num_classes = 80\n",
    "classes = load_classes(\"../data/coco.names\")\n",
    "\n",
    "#Set up the neural network\n",
    "\n",
    "print(\"Loading network.....\")\n",
    "model = Darknet(\"cfg/yolov4.cfg\")\n",
    "print(\"Edit conv layer 114 (layer after SPP)\")\n",
    "model.module_list[114].conv_114 = nn.Conv2d(2048, 512, kernel_size=(1,1), stride=(1,1), bias=False)\n",
    "model.load_weights(\"yolov4.weights\")\n",
    "print(\"Network successfully loaded\")\n",
    "\n",
    "model.net_info[\"height\"] = 416\n",
    "inp_dim = int(model.net_info[\"height\"])\n",
    "assert inp_dim % 32 == 0 \n",
    "assert inp_dim > 32\n",
    "\n",
    "#If there's a GPU availible, put the model on GPU\n",
    "\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "# Set the model in evaluation mode\n",
    "\n",
    "model.eval()\n",
    "\n",
    "read_dir = time.time()\n",
    "\n",
    "# Detection phase\n",
    "\n",
    "imlist = [3]\n",
    "\n",
    "try:\n",
    "    imlist = [osp.join(osp.realpath('.'), images, img) for img in os.listdir(images)]\n",
    "except NotADirectoryError:\n",
    "    imlist = []\n",
    "    imlist.append(osp.join(osp.realpath('.'), images))\n",
    "except FileNotFoundError:\n",
    "    print (\"No file or directory with the name {}\".format(images))\n",
    "    exit()\n",
    "\n",
    "print(imlist)\n",
    "    \n",
    "if not os.path.exists(\"des\"):\n",
    "    os.makedirs(\"des\")\n",
    "\n",
    "load_batch = time.time()\n",
    "loaded_ims = [cv2.imread(x) for x in imlist]\n",
    "\n",
    "im_batches = list(map(prep_image, loaded_ims, [inp_dim for x in range(len(imlist))]))\n",
    "im_dim_list = [(x.shape[1], x.shape[0]) for x in loaded_ims]\n",
    "im_dim_list = torch.FloatTensor(im_dim_list).repeat(1,2)\n",
    "\n",
    "\n",
    "leftover = 0\n",
    "if (len(im_dim_list) % batch_size):\n",
    "    leftover = 1\n",
    "\n",
    "if batch_size != 1:\n",
    "    num_batches = len(imlist) // batch_size + leftover            \n",
    "    im_batches = [torch.cat((im_batches[i*batch_size : min((i +  1)*batch_size,\n",
    "                        len(im_batches))]))  for i in range(num_batches)]  \n",
    "\n",
    "write = 0\n",
    "\n",
    "if CUDA:\n",
    "    im_dim_list = im_dim_list.cuda()\n",
    "    \n",
    "start_det_loop = time.time()\n",
    "for i, batch in enumerate(im_batches):\n",
    "    # Load the image \n",
    "    start = time.time()\n",
    "    if CUDA:\n",
    "        batch = batch.cuda()\n",
    "    with torch.no_grad():\n",
    "        prediction = model(Variable(batch), CUDA)\n",
    "\n",
    "    prediction = write_results(prediction, confidence, num_classes, nms_conf = nms_thesh)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    if type(prediction) == int:\n",
    "\n",
    "        for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
    "            im_id = i*batch_size + im_num\n",
    "            print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
    "            print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \"\"))\n",
    "            print(\"----------------------------------------------------------\")\n",
    "        continue\n",
    "\n",
    "    prediction[:,0] += i*batch_size    #transform the atribute from index in batch to index in imlist \n",
    "\n",
    "    if not write:                      #If we have't initialised output\n",
    "        output = prediction  \n",
    "        write = 1\n",
    "    else:\n",
    "        output = torch.cat((output,prediction))\n",
    "\n",
    "    for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
    "        im_id = i*batch_size + im_num\n",
    "        objs = [classes[int(x[-1])] for x in output if int(x[0]) == im_id]\n",
    "        print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
    "        print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \" \".join(objs)))\n",
    "        print(\"----------------------------------------------------------\")\n",
    "\n",
    "    if CUDA:\n",
    "        torch.cuda.synchronize()       \n",
    "try:\n",
    "    output\n",
    "except NameError:\n",
    "    print (\"No detections were made\")\n",
    "    exit()\n",
    "\n",
    "im_dim_list = torch.index_select(im_dim_list, 0, output[:,0].long())\n",
    "\n",
    "scaling_factor = torch.min(416/im_dim_list,1)[0].view(-1,1)\n",
    "\n",
    "output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim_list[:,0].view(-1,1))/2\n",
    "output[:,[2,4]] -= (inp_dim - scaling_factor*im_dim_list[:,1].view(-1,1))/2\n",
    "\n",
    "output[:,1:5] /= scaling_factor\n",
    "\n",
    "for i in range(output.shape[0]):\n",
    "    output[i, [1,3]] = torch.clamp(output[i, [1,3]], 0.0, im_dim_list[i,0])\n",
    "    output[i, [2,4]] = torch.clamp(output[i, [2,4]], 0.0, im_dim_list[i,1])\n",
    "    \n",
    "output_recast = time.time()\n",
    "class_load = time.time()\n",
    "colors = [[255, 0, 0], [255, 0, 0], [255, 255, 0], [0, 255, 0], [0, 255, 255], [0, 0, 255], [255, 0, 255]]\n",
    "\n",
    "draw = time.time()\n",
    "\n",
    "def write(x, results):\n",
    "    c1 = tuple(x[1:3].int())\n",
    "    c2 = tuple(x[3:5].int())\n",
    "    img = results[int(x[0])]\n",
    "    cls = int(x[-1])\n",
    "    color = random.choice(colors)\n",
    "    label = \"{0}\".format(classes[cls])\n",
    "    cv2.rectangle(img, c1, c2,color, 1)\n",
    "    t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1 , 1)[0]\n",
    "    c2 = c1[0] + t_size[0] + 3, c1[1] + t_size[1] + 4\n",
    "    cv2.rectangle(img, c1, c2,color, -1)\n",
    "    cv2.putText(img, label, (c1[0], c1[1] + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [225,255,255], 1);\n",
    "    return img\n",
    "\n",
    "\n",
    "list(map(lambda x: write(x, loaded_ims), output))\n",
    "\n",
    "det_names = pd.Series(imlist).apply(lambda x: \"{}/det_{}\".format(\"des\",x.split(\"/\")[-1]))\n",
    "\n",
    "list(map(cv2.imwrite, det_names, loaded_ims))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"SUMMARY\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"{:25s}: {}\".format(\"Task\", \"Time Taken (in seconds)\"))\n",
    "print()\n",
    "print(\"{:25s}: {:2.3f}\".format(\"Reading addresses\", load_batch - read_dir))\n",
    "print(\"{:25s}: {:2.3f}\".format(\"Loading batch\", start_det_loop - load_batch))\n",
    "print(\"{:25s}: {:2.3f}\".format(\"Detection (\" + str(len(imlist)) +  \" images)\", output_recast - start_det_loop))\n",
    "print(\"{:25s}: {:2.3f}\".format(\"Output Processing\", class_load - output_recast))\n",
    "print(\"{:25s}: {:2.3f}\".format(\"Drawing Boxes\", end - draw))\n",
    "print(\"{:25s}: {:2.3f}\".format(\"Average time_per_img\", (end - load_batch)/len(imlist)))\n",
    "print(\"----------------------------------------------------------\")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}